{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUSTOM LOSS FUNCTIONS\n",
    "#### *1. HUBER LOSS FUNCTION*\n",
    "\n",
    "+ Suppose you are training a Regression Model.\n",
    "+ But your data is noisy.\n",
    "+ So you will clean the data and remove or fix the Outliers.\n",
    "+ But Still the data is noisy.\n",
    "+ So which loss function will you use.\n",
    "+ If we use MSE, it might not penalize the large error.\n",
    "+ If we use MAE, it woud not penalize outliers.\n",
    "+ Here we are Implementing the Huber Loss Function.\n",
    "+ It is available on `keras.losses.huber`\n",
    "+ But we are trying to Implement that functionally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x252 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "## defining the huber function\n",
    "## this is the loss function\n",
    "def huber_fn(y_true, y_pred):\n",
    "    ## define the error from y_true and y_pred, that will be the difference\n",
    "    error = y_true - y_pred\n",
    "    #print(error)\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "\n",
    "plt.figure(figsize=(8, 3.5))\n",
    "z = np.linspace(-4, 4, 200)\n",
    "plt.plot(z, huber_fn(0, z), \"b-\", linewidth=2, label=\"huber($z$)\")\n",
    "plt.plot(z, z**2 / 2, \"b:\", linewidth=1, label=r\"$\\frac{1}{2}z^2$\")\n",
    "plt.plot([-1, -1], [0, huber_fn(0., -1.)], \"r--\")\n",
    "plt.plot([1, 1], [0, huber_fn(0., 1.)], \"r--\")\n",
    "plt.gca().axhline(y=0, color='k')\n",
    "plt.gca().axvline(x=0, color='k')\n",
    "plt.axis([-4, 4, 0, 4])\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"$z$\")\n",
    "plt.legend(fontsize=14)\n",
    "plt.title(\"Huber loss\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'feature_names', 'DESCR'])\n",
      "\n",
      "====================================Complete Dataset======================================\n",
      "(15480, 8)\n",
      "(5160, 8)\n",
      "(15480, 1)\n",
      "(5160, 1)\n",
      "\n",
      "====================================Dataset After Splitting to Validation Set======================================\n",
      "(11610, 8)\n",
      "(3870, 8)\n",
      "(11610, 1)\n",
      "(3870, 1)\n",
      "\n",
      "=================================Standardize the Data==============================================\n",
      "(11610, 8)\n",
      "(3870, 8)\n",
      "(5160, 8)\n",
      "=================================Defining and Develop the Model===================================\n",
      "(8,)\n",
      "=============================Compile the Model=================================\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 30)                270       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "=================================Train the Model=======================================\n",
      "Epoch 1/20\n",
      "363/363 [==============================] - 2s 2ms/step - loss: 13.9860 - mae: 14.4667 - val_loss: 1.5951 - val_mae: 2.0533\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 3.6076 - mae: 4.0824 - val_loss: 1.5940 - val_mae: 2.0566\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 3.2527 - mae: 3.7262 - val_loss: 1.5993 - val_mae: 2.0650\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 3.1089 - mae: 3.5846 - val_loss: 1.6020 - val_mae: 2.0689\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.8955 - mae: 3.3697 - val_loss: 1.6014 - val_mae: 2.0673\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.6164 - mae: 3.0846 - val_loss: 1.6057 - val_mae: 2.0733\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.5751 - mae: 3.0454 - val_loss: 1.6081 - val_mae: 2.0732\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.4387 - mae: 2.9083 - val_loss: 1.6093 - val_mae: 2.0760\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.2568 - mae: 2.7219 - val_loss: 1.6091 - val_mae: 2.0744\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.2067 - mae: 2.6740 - val_loss: 1.6162 - val_mae: 2.0829\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.0895 - mae: 2.5526 - val_loss: 1.6127 - val_mae: 2.0775\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.9699 - mae: 2.4306 - val_loss: 1.6172 - val_mae: 2.0810\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.9099 - mae: 2.3722 - val_loss: 1.6173 - val_mae: 2.0808\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.7929 - mae: 2.2489 - val_loss: 1.6164 - val_mae: 2.0785\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.7600 - mae: 2.2162 - val_loss: 1.6246 - val_mae: 2.0888\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.6819 - mae: 2.1351 - val_loss: 1.6277 - val_mae: 2.0904\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.6176 - mae: 2.0709 - val_loss: 1.6329 - val_mae: 2.0962\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.5596 - mae: 2.0091 - val_loss: 1.6333 - val_mae: 2.0957\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.5247 - mae: 1.9764 - val_loss: 1.6362 - val_mae: 2.0990\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.4625 - mae: 1.9100 - val_loss: 1.6336 - val_mae: 2.0960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ab3e476130>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## fetch the data.\n",
    "housing = fetch_california_housing()\n",
    "# housing.data\n",
    "# housing.target\n",
    "print(housing.keys())\n",
    "print()\n",
    "print(\"====================================Complete Dataset======================================\")\n",
    "## X_train_full, X_test, y_train_full, y_test\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target.reshape(-1,1), random_state = 42)\n",
    "print(X_train_full.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train_full.shape)\n",
    "print(y_test.shape)\n",
    "print()\n",
    "print(\"====================================Dataset After Splitting to Validation Set======================================\")\n",
    "## X_valid, X_test, y_valid, y_test\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_train.shape)\n",
    "print(y_valid.shape)\n",
    "print()\n",
    "\n",
    "print(\"=================================Standardize the Data==============================================\")\n",
    "## Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "print(X_train_scaled.shape)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "print(y_valid_scaled.shape)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print(X_test_scaled.shape)\n",
    "\n",
    "print(\"=================================Defining and Develop the Model===================================\")\n",
    "## defining the input shape\n",
    "input_shape = X_train.shape[1:]\n",
    "print(input_shape)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation = \"selu\", kernel_initializer = \"lecun_normal\", input_shape = input_shape),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "print(\"=============================Compile the Model=================================\")\n",
    "model.compile(loss = huber_fn, optimizer = \"nadam\", metrics = [\"mae\"])\n",
    "print(model.summary())\n",
    "\n",
    "print(\"=================================Train the Model=======================================\")\n",
    "model.fit(X_train, y_train, epochs = 20, validation_data = (X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================Compile the Model=================================\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 30)                270       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "=================================Train the Model=======================================\n",
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 3.0943 - mse: 23.9494 - val_loss: 1.6247 - val_mse: 6.0515\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.8963 - mse: 20.5328 - val_loss: 1.6254 - val_mse: 6.0609\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.7873 - mse: 19.5649 - val_loss: 1.6263 - val_mse: 6.0848\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.6330 - mse: 17.6647 - val_loss: 1.6249 - val_mse: 6.0981\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.4754 - mse: 15.5721 - val_loss: 1.6230 - val_mse: 6.0841\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.3774 - mse: 14.3395 - val_loss: 1.6231 - val_mse: 6.0703\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.2228 - mse: 13.3213 - val_loss: 1.6276 - val_mse: 6.1204\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.1637 - mse: 12.8238 - val_loss: 1.6225 - val_mse: 6.0962\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.0535 - mse: 11.6782 - val_loss: 1.6235 - val_mse: 6.1152\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.9950 - mse: 10.8736 - val_loss: 1.6212 - val_mse: 6.1122\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.8775 - mse: 9.7929 - val_loss: 1.6230 - val_mse: 6.1299\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.8080 - mse: 9.3198 - val_loss: 1.6202 - val_mse: 6.1069\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.6887 - mse: 8.4772 - val_loss: 1.6206 - val_mse: 6.1009\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.6505 - mse: 8.2729 - val_loss: 1.6213 - val_mse: 6.1062\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.5829 - mse: 7.9503 - val_loss: 1.6215 - val_mse: 6.1222\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.5173 - mse: 7.0906 - val_loss: 1.6236 - val_mse: 6.1145\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.4855 - mse: 6.9276 - val_loss: 1.6176 - val_mse: 6.0720\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.4242 - mse: 6.6397 - val_loss: 1.6173 - val_mse: 6.0812\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3826 - mse: 6.2131 - val_loss: 1.6150 - val_mse: 6.0564\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.2584 - mse: 5.3974 - val_loss: 1.6156 - val_mse: 6.0473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ab478ff970>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## training the model using the mse metrics\n",
    "print(\"=============================Compile the Model=================================\")\n",
    "model.compile(loss = huber_fn, optimizer = \"nadam\", metrics = [\"mse\"])\n",
    "print(model.summary())\n",
    "\n",
    "print(\"=================================Train the Model=======================================\")\n",
    "model.fit(X_train, y_train, epochs = 20, validation_data = (X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the model\n",
    "model.save(\"my_model_with_a_custom_loss.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *2. SAVING AND LOADNG THE MODELS THAT CONTAIN CUSTOM COMPONENTS*\n",
    "\n",
    "+ When you load a model containing custom objects you need to map the name to the objects.\n",
    "+ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3862 - mse: 1.1175 - val_loss: 0.2800 - val_mse: 6.5311\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2275 - mse: 0.5973 - val_loss: 0.2512 - val_mse: 4.5090\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2150 - mse: 0.5376 - val_loss: 0.2359 - val_mse: 3.2253\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2097 - mse: 0.5149 - val_loss: 0.2223 - val_mse: 2.1146\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2058 - mse: 0.4925 - val_loss: 0.2108 - val_mse: 1.2770\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2030 - mse: 0.4809 - val_loss: 0.1959 - val_mse: 0.6308\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2003 - mse: 0.4667 - val_loss: 0.1837 - val_mse: 0.4208\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1978 - mse: 0.4594 - val_loss: 0.1892 - val_mse: 0.5425\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1960 - mse: 0.4563 - val_loss: 0.1806 - val_mse: 0.4156\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1942 - mse: 0.4509 - val_loss: 0.1782 - val_mse: 0.4043\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1925 - mse: 0.4459 - val_loss: 0.1766 - val_mse: 0.4026\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1905 - mse: 0.4395 - val_loss: 0.1844 - val_mse: 0.5895\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1893 - mse: 0.4369 - val_loss: 0.1762 - val_mse: 0.4154\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1874 - mse: 0.4312 - val_loss: 0.1766 - val_mse: 0.4452\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1861 - mse: 0.4261 - val_loss: 0.1710 - val_mse: 0.3900\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1847 - mse: 0.4242 - val_loss: 0.1838 - val_mse: 0.6842\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1834 - mse: 0.4205 - val_loss: 0.1725 - val_mse: 0.4053\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1816 - mse: 0.4156 - val_loss: 0.1715 - val_mse: 0.3967\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1806 - mse: 0.4123 - val_loss: 0.1867 - val_mse: 1.0021\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1804 - mse: 0.4150 - val_loss: 0.1731 - val_mse: 0.4880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ab489ec9d0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## when you load the model, need to specify the name of the object.\n",
    "model = keras.models.load_model(\"my_model_with_a_custom_loss.h5\", custom_objects = {\"huber_fn\":huber_fn})\n",
    "## train the model.\n",
    "model.fit(X_train_scaled, y_train, epochs=20,validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ any error between -1 and 1 considered as small.\n",
    "+ But if you want different threshold, we will have to build new function for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================Compile the Model=================================\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 30)                270       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "=================================Train the Model=======================================\n",
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 6.5918 - mae: 4.2092 - val_loss: 0.2580 - val_mae: 0.5239\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 5.3298 - mae: 3.5683 - val_loss: 0.2688 - val_mae: 0.5278\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 4.9270 - mae: 3.3594 - val_loss: 0.2885 - val_mae: 0.5426\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 4.5244 - mae: 3.1509 - val_loss: 0.3092 - val_mae: 0.5576\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 4.2260 - mae: 2.9928 - val_loss: 0.3256 - val_mae: 0.5652\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 3.9571 - mae: 2.8561 - val_loss: 0.3308 - val_mae: 0.5652\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 3.7301 - mae: 2.7378 - val_loss: 0.3478 - val_mae: 0.5798\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 3.3979 - mae: 2.5473 - val_loss: 0.3528 - val_mae: 0.5830\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 3.3015 - mae: 2.4959 - val_loss: 0.3583 - val_mae: 0.5860\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 3.1705 - mae: 2.4299 - val_loss: 0.3706 - val_mae: 0.5942\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.9385 - mae: 2.3027 - val_loss: 0.3714 - val_mae: 0.5955\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.7810 - mae: 2.2193 - val_loss: 0.3803 - val_mae: 0.5998\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.6116 - mae: 2.1145 - val_loss: 0.3941 - val_mae: 0.6123\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.5629 - mae: 2.0940 - val_loss: 0.3946 - val_mae: 0.6091\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.3221 - mae: 1.9515 - val_loss: 0.4046 - val_mae: 0.6194\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.2478 - mae: 1.9103 - val_loss: 0.4040 - val_mae: 0.6180\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.1935 - mae: 1.8798 - val_loss: 0.3984 - val_mae: 0.6123\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.9815 - mae: 1.7438 - val_loss: 0.3969 - val_mae: 0.6085\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.9566 - mae: 1.7356 - val_loss: 0.3978 - val_mae: 0.6092\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.9413 - mae: 1.7325 - val_loss: 0.4095 - val_mae: 0.6186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ab49beffa0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_huber(threshold=1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = threshold * tf.abs(error) - threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    return huber_fn\n",
    "\n",
    "## training the model using the mse metrics\n",
    "print(\"=============================Compile the Model=================================\")\n",
    "model.compile(loss = create_huber(2.0), optimizer = \"nadam\", metrics = [\"mae\"])\n",
    "print(model.summary())\n",
    "\n",
    "print(\"=================================Train the Model=======================================\")\n",
    "model.fit(X_train, y_train, epochs = 20, validation_data = (X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## saving the latest model\n",
    "model.save(\"my_model_with_a_custom_loss_threshold_2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ when the model is saved, the threshold will not get saved.\n",
    "+ So when you load the model, we have to specify the threshold value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================Train the Model=======================================\n",
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.8387 - mae: 1.6689 - val_loss: 0.4120 - val_mae: 0.6215\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.6924 - mae: 1.5631 - val_loss: 0.4151 - val_mae: 0.6245\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.6804 - mae: 1.5697 - val_loss: 0.4152 - val_mae: 0.6233\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.5833 - mae: 1.4992 - val_loss: 0.4195 - val_mae: 0.6259\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.5996 - mae: 1.5261 - val_loss: 0.4246 - val_mae: 0.6311\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.4970 - mae: 1.4609 - val_loss: 0.4280 - val_mae: 0.6326\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.5177 - mae: 1.4651 - val_loss: 0.4340 - val_mae: 0.6373\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3911 - mae: 1.3910 - val_loss: 0.4327 - val_mae: 0.6371\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3766 - mae: 1.3766 - val_loss: 0.4456 - val_mae: 0.6484\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3629 - mae: 1.3625 - val_loss: 0.4394 - val_mae: 0.6421\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3001 - mae: 1.3272 - val_loss: 0.4360 - val_mae: 0.6397\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3379 - mae: 1.3548 - val_loss: 0.4343 - val_mae: 0.6398\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.2795 - mae: 1.3199 - val_loss: 0.4425 - val_mae: 0.6463\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.2084 - mae: 1.2793 - val_loss: 0.4428 - val_mae: 0.6473\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.1634 - mae: 1.2265 - val_loss: 0.4465 - val_mae: 0.6496\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.1885 - mae: 1.2460 - val_loss: 0.4515 - val_mae: 0.6535\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.1969 - mae: 1.2553 - val_loss: 0.4461 - val_mae: 0.6478\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.1349 - mae: 1.2131 - val_loss: 0.4518 - val_mae: 0.6545\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.1112 - mae: 1.2023 - val_loss: 0.4503 - val_mae: 0.6527\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.1479 - mae: 1.2208 - val_loss: 0.4636 - val_mae: 0.6655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ab4aea4430>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_loss_threshold_2.h5\",\n",
    "                                custom_objects={\"huber_fn\": create_huber(2.0)})\n",
    "print(\"=================================Train the Model=======================================\")\n",
    "model.fit(X_train, y_train, epochs = 20, validation_data = (X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DOING THE SAME USING A CLASS OBJECT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============DEVELOP THE MODEL==================\n",
      "=============COMPILE THE MODEL===================\n",
      "==============TRAIN THE MODEL====================\n",
      "Epoch 1/20\n",
      "363/363 [==============================] - 2s 2ms/step - loss: 0.8213 - mae: 0.9919 - val_loss: 0.2731 - val_mae: 0.5192\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2324 - mae: 0.5046 - val_loss: 0.2461 - val_mae: 0.5001\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2254 - mae: 0.4964 - val_loss: 0.2251 - val_mae: 0.4883\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2217 - mae: 0.4920 - val_loss: 0.2124 - val_mae: 0.4765\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2182 - mae: 0.4884 - val_loss: 0.2028 - val_mae: 0.4714\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2155 - mae: 0.4851 - val_loss: 0.2263 - val_mae: 0.4809\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2119 - mae: 0.4798 - val_loss: 0.2096 - val_mae: 0.4724\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2106 - mae: 0.4784 - val_loss: 0.2065 - val_mae: 0.4679\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2082 - mae: 0.4746 - val_loss: 0.2419 - val_mae: 0.4852\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2070 - mae: 0.4727 - val_loss: 0.2147 - val_mae: 0.4730\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2054 - mae: 0.4715 - val_loss: 0.1897 - val_mae: 0.4504\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2030 - mae: 0.4675 - val_loss: 0.2208 - val_mae: 0.4746\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2015 - mae: 0.4657 - val_loss: 0.2204 - val_mae: 0.4650\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2008 - mae: 0.4638 - val_loss: 0.2244 - val_mae: 0.4661\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1991 - mae: 0.4621 - val_loss: 0.2218 - val_mae: 0.4642\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1983 - mae: 0.4604 - val_loss: 0.2237 - val_mae: 0.4648\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1959 - mae: 0.4568 - val_loss: 0.2132 - val_mae: 0.4567\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1952 - mae: 0.4557 - val_loss: 0.2118 - val_mae: 0.4566\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1942 - mae: 0.4540 - val_loss: 0.2059 - val_mae: 0.4567\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1937 - mae: 0.4536 - val_loss: 0.2016 - val_mae: 0.4484\n",
      "==============SAVE THE MODEL======================\n"
     ]
    }
   ],
   "source": [
    "class HuberLoss(keras.losses.Loss):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = self.threshold * tf.abs(error) - self.threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}\n",
    "    \n",
    "print(\"==============DEVELOP THE MODEL==================\")\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "print(\"=============COMPILE THE MODEL===================\")\n",
    "model.compile(loss=HuberLoss(2.), optimizer=\"nadam\", metrics=[\"mae\"])\n",
    "\n",
    "print(\"==============TRAIN THE MODEL====================\")\n",
    "model.fit(X_train_scaled, y_train, epochs=20,validation_data=(X_valid_scaled, y_valid))\n",
    "\n",
    "print(\"==============SAVE THE MODEL======================\")\n",
    "model.save(\"my_model_with_a_custom_loss_class.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1914 - mae: 0.4491 - val_loss: 0.2410 - val_mae: 0.4732\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1913 - mae: 0.4478 - val_loss: 0.2148 - val_mae: 0.4615\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1903 - mae: 0.4481 - val_loss: 0.2413 - val_mae: 0.4701\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1903 - mae: 0.4462 - val_loss: 0.1898 - val_mae: 0.4384\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1879 - mae: 0.4439 - val_loss: 0.1997 - val_mae: 0.4456\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1880 - mae: 0.4437 - val_loss: 0.2135 - val_mae: 0.4538\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1874 - mae: 0.4428 - val_loss: 0.1828 - val_mae: 0.4407\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1852 - mae: 0.4403 - val_loss: 0.1885 - val_mae: 0.4370\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1845 - mae: 0.4394 - val_loss: 0.2147 - val_mae: 0.4470\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1849 - mae: 0.4387 - val_loss: 0.2199 - val_mae: 0.4489\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1842 - mae: 0.4385 - val_loss: 0.2269 - val_mae: 0.4529\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1835 - mae: 0.4366 - val_loss: 0.2325 - val_mae: 0.4603\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1833 - mae: 0.4361 - val_loss: 0.1963 - val_mae: 0.4398\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1816 - mae: 0.4347 - val_loss: 0.2245 - val_mae: 0.4529\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1821 - mae: 0.4351 - val_loss: 0.2145 - val_mae: 0.4457\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1814 - mae: 0.4340 - val_loss: 0.2126 - val_mae: 0.4447\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1801 - mae: 0.4319 - val_loss: 0.2236 - val_mae: 0.4584\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1801 - mae: 0.4317 - val_loss: 0.2224 - val_mae: 0.4500\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1792 - mae: 0.4305 - val_loss: 0.1837 - val_mae: 0.4248\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1793 - mae: 0.4301 - val_loss: 0.2114 - val_mae: 0.4418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ab4d214340>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## loading the model\n",
    "model = keras.models.load_model(\"my_model_with_a_custom_loss_class.h5\",\n",
    "                                custom_objects={\"HuberLoss\": HuberLoss})\n",
    "\n",
    "## train the model again.\n",
    "model.fit(X_train_scaled, y_train, epochs=20,validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss.threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ When the model is saved, the threshold will be saved along with it.\n",
    "+ When the model is load, you just need to map the class name to the class itself.\n",
    "\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
