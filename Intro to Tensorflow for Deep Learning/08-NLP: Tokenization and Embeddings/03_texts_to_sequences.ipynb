{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **TEXT TO SEQUENCES**\n",
        "\n",
        "+ Now we have created Sequences from Sentences.\n",
        "+ In steps to Prepare the data.\n",
        "  + Tokenize the Words.\n",
        "  + Create Sequences from the Sentences.\n",
        "  + Make the Sequence all the same length.\n",
        "+ Use Padding and Truncating to make the Sequence all the Same Length.\n",
        "\n",
        "**PADDING AND TRUNCATING**\n",
        "\n",
        "+ By default, pad_sequences pad to the longest sequence.\n",
        "+ Specify the `maxlen` to set the length of the Sequence.\n",
        "+ By default, Sequences are padded or truncated at the beginning of the Sequence.\n",
        "+ Specify `padding = \"post\"` to pad from the end of the Sequence.\n",
        "+ Specify `truncating = \"post\"` to truncate from the end of the Sequence."
      ],
      "metadata": {
        "id": "EZvP-bfX_LWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORTS "
      ],
      "metadata": {
        "id": "whMa37CpFFeT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Tokenizer and pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "dfCckE-d_OvN"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## define some sentences\n",
        "sentences = [\n",
        "    'My favorite food is ice cream',\n",
        "    'do you like ice cream too?',\n",
        "    'My dog likes ice cream!',\n",
        "    \"your favorite flavor of icecream is chocolate\",\n",
        "    \"chocolate isn't good for dogs\",\n",
        "    \"your dog, your cat, and your parrot prefer broccoli\"\n",
        "]\n",
        "print(sentences)\n",
        "\n",
        "## When creating the Tokenizer, \n",
        "## you can specify the max number of words in the dictionary. \n",
        "## You can also specify a token to represent words that are out of the vocabulary (OOV), \n",
        "## in other words, that are not in the dictionary. \n",
        "##This OOV token will be used when you create sequences for sentences that contain words that are not in the word index.\n",
        "tokenizer = Tokenizer(num_words = 100, oov_token=\"<OOV>\")\n",
        "## tokenize the words using fit_on_texts\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "print(word_index)\n",
        "\n",
        "## So the next step to representing text in a way that can be meaningfully used by machine learning programs \n",
        "## is to create numerical sequences that represent the sentences in the text.\n",
        "## Each sentence will be converted into a sequence where each word is replaced by its number in the word index.\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "print(\"\\nSequences :-\",sequences)\n",
        "\n",
        "## do padding here we are doing the padding. not truncating\n",
        "## we can do padding alone.\n",
        "## we can do truncating\n",
        "## and padding and truncating together.\n",
        "## notes are present in the Bio\n",
        "padded = pad_sequences(sequences)\n",
        "print(\"\\nWord Index = \" , word_index)\n",
        "print(\"\\nSequences = \" , sequences)\n",
        "print(\"\\nPadded Sequences:\")\n",
        "print(padded)\n",
        "\n",
        "# Specify a max length for the padded sequences\n",
        "padded = pad_sequences(sequences, maxlen=15)\n",
        "print(\"\\nPadded Sequence with length 15 :--\",padded)\n",
        "\n",
        "# Put the padding at the end of the sequences\n",
        "padded = pad_sequences(sequences, maxlen=15, padding=\"post\")\n",
        "print(\"\\nPadding at the End of the Sequence with length 15 :-\",padded)\n",
        "\n",
        "# Limit the length of the sequences, you will see some sequences get truncated\n",
        "## this will happen in the beggining, the truncating operation.\n",
        "padded = pad_sequences(sequences, maxlen=3)\n",
        "print(\"\\nTruncated Sequences to the Length 3 :-\",padded)\n",
        "\n",
        "## truncating to the end of the sequences.\n",
        "padded = pad_sequences(sequences, maxlen=3, padding = \"post\")\n",
        "print(\"\\nTruncated Sequences to the end by Length 3 :-\",padded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPiCA5ZlFG9F",
        "outputId": "80771ee7-013d-4af4-c399-26e7bf1054be"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['My favorite food is ice cream', 'do you like ice cream too?', 'My dog likes ice cream!', 'your favorite flavor of icecream is chocolate', \"chocolate isn't good for dogs\", 'your dog, your cat, and your parrot prefer broccoli']\n",
            "{'<OOV>': 1, 'your': 2, 'ice': 3, 'cream': 4, 'my': 5, 'favorite': 6, 'is': 7, 'dog': 8, 'chocolate': 9, 'food': 10, 'do': 11, 'you': 12, 'like': 13, 'too': 14, 'likes': 15, 'flavor': 16, 'of': 17, 'icecream': 18, \"isn't\": 19, 'good': 20, 'for': 21, 'dogs': 22, 'cat': 23, 'and': 24, 'parrot': 25, 'prefer': 26, 'broccoli': 27}\n",
            "\n",
            "Sequences :- [[5, 6, 10, 7, 3, 4], [11, 12, 13, 3, 4, 14], [5, 8, 15, 3, 4], [2, 6, 16, 17, 18, 7, 9], [9, 19, 20, 21, 22], [2, 8, 2, 23, 24, 2, 25, 26, 27]]\n",
            "\n",
            "Word Index =  {'<OOV>': 1, 'your': 2, 'ice': 3, 'cream': 4, 'my': 5, 'favorite': 6, 'is': 7, 'dog': 8, 'chocolate': 9, 'food': 10, 'do': 11, 'you': 12, 'like': 13, 'too': 14, 'likes': 15, 'flavor': 16, 'of': 17, 'icecream': 18, \"isn't\": 19, 'good': 20, 'for': 21, 'dogs': 22, 'cat': 23, 'and': 24, 'parrot': 25, 'prefer': 26, 'broccoli': 27}\n",
            "\n",
            "Sequences =  [[5, 6, 10, 7, 3, 4], [11, 12, 13, 3, 4, 14], [5, 8, 15, 3, 4], [2, 6, 16, 17, 18, 7, 9], [9, 19, 20, 21, 22], [2, 8, 2, 23, 24, 2, 25, 26, 27]]\n",
            "\n",
            "Padded Sequences:\n",
            "[[ 0  0  0  5  6 10  7  3  4]\n",
            " [ 0  0  0 11 12 13  3  4 14]\n",
            " [ 0  0  0  0  5  8 15  3  4]\n",
            " [ 0  0  2  6 16 17 18  7  9]\n",
            " [ 0  0  0  0  9 19 20 21 22]\n",
            " [ 2  8  2 23 24  2 25 26 27]]\n",
            "\n",
            "Padded Sequence with length 15 :-- [[ 0  0  0  0  0  0  0  0  0  5  6 10  7  3  4]\n",
            " [ 0  0  0  0  0  0  0  0  0 11 12 13  3  4 14]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  5  8 15  3  4]\n",
            " [ 0  0  0  0  0  0  0  0  2  6 16 17 18  7  9]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  9 19 20 21 22]\n",
            " [ 0  0  0  0  0  0  2  8  2 23 24  2 25 26 27]]\n",
            "\n",
            "Padding at the End of the Sequence with length 15 :- [[ 5  6 10  7  3  4  0  0  0  0  0  0  0  0  0]\n",
            " [11 12 13  3  4 14  0  0  0  0  0  0  0  0  0]\n",
            " [ 5  8 15  3  4  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 2  6 16 17 18  7  9  0  0  0  0  0  0  0  0]\n",
            " [ 9 19 20 21 22  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 2  8  2 23 24  2 25 26 27  0  0  0  0  0  0]]\n",
            "\n",
            "Truncated Sequences to the Length 3 :- [[ 7  3  4]\n",
            " [ 3  4 14]\n",
            " [15  3  4]\n",
            " [18  7  9]\n",
            " [20 21 22]\n",
            " [25 26 27]]\n",
            "\n",
            "Truncated Sequences to the end by Length 3 :- [[ 7  3  4]\n",
            " [ 3  4 14]\n",
            " [15  3  4]\n",
            " [18  7  9]\n",
            " [20 21 22]\n",
            " [25 26 27]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What happens if some of the sentences contain words that are not in the word index?\n",
        "\n",
        "Try generating sequences for some sentences that have words that are not in the word index."
      ],
      "metadata": {
        "id": "LMYKNV_fIMCk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Try turning sentences that contain words that \n",
        "# aren't in the word index into sequences.\n",
        "# Add your own sentences to the test_data\n",
        "test_data = [\n",
        "    \"my best friend's favorite ice cream flavor is strawberry\",\n",
        "    \"my dog's best friend is a manatee\"\n",
        "]\n",
        "print (test_data)\n",
        "\n",
        "# Remind ourselves which number corresponds to the\n",
        "# out of vocabulary token in the word index\n",
        "print(\"<OOV> has the number\", word_index['<OOV>'], \"in the word index.\")\n",
        "\n",
        "# Convert the test sentences to sequences\n",
        "test_seq = tokenizer.texts_to_sequences(test_data)\n",
        "print(\"\\nTest Sequence = \", test_seq)\n",
        "\n",
        "# Pad the new sequences\n",
        "padded = pad_sequences(test_seq, maxlen=10)\n",
        "print(\"\\nPadded Test Sequence: \")\n",
        "\n",
        "# Notice that \"1\" appears in the sequence wherever there's a word \n",
        "# that's not in the word index\n",
        "print(padded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTsmMpLYHX7E",
        "outputId": "62a210df-d0f2-4fae-acf5-2f4c950a09bc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"my best friend's favorite ice cream flavor is strawberry\", \"my dog's best friend is a manatee\"]\n",
            "<OOV> has the number 1 in the word index.\n",
            "\n",
            "Test Sequence =  [[5, 1, 1, 6, 3, 4, 16, 7, 1], [5, 1, 1, 1, 7, 1, 1]]\n",
            "\n",
            "Padded Test Sequence: \n",
            "[[ 0  5  1  1  6  3  4 16  7  1]\n",
            " [ 0  0  0  5  1  1  1  7  1  1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***"
      ],
      "metadata": {
        "id": "gV4PkGn1IdyC"
      }
    }
  ]
}