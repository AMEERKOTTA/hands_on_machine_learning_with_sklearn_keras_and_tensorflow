{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PREPARE THE DATA FOR MACHINE LEARNING ALGORITHMS**\n",
    "\n",
    "+ We will be writing Functions for this Purpose.\n",
    "\n",
    "        + Which will help to use the funtionalized code for other Problems.\n",
    "        \n",
    "        + Helps to build libraries for Transformations.\n",
    "        \n",
    "\n",
    "\n",
    "+ Steps are :--\n",
    "\n",
    "    + Data Cleaning  :-- SimpleImputer\n",
    "    \n",
    "    + Handling Text Attributes.  :-- OrdinalEncoder\n",
    "    \n",
    "    + Handling Categorical Attributes.  :-- OneHotEncoder\n",
    "    \n",
    "    + Building Custom Transformers.\n",
    "    \n",
    "    + Feature Scaling.\n",
    "    \n",
    "    + Transformation Pipelines.\n",
    "    \n",
    "    + and more Explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv(\"housing.csv\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(housing, test_size = 0.2, random_state = 42)\n",
    "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n",
    "                              bins = [0.0, 1.5, 3.0, 4.5, 6.0, np.inf],\n",
    "                              labels = [1,2,3,4,5])\n",
    "## stratified Splitting\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)\n",
    "\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "    #print(train_index), print(len(train_index))\n",
    "    #print(test_index), print(len(test_index))\n",
    "    \n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    #print(strat_train_set)\n",
    "    strat_test_set = housing.loc[test_index]\n",
    "    #print(strat_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 11)\n",
      "(16512, 11)\n",
      "(4128, 11)\n"
     ]
    }
   ],
   "source": [
    "print(housing.shape)\n",
    "print(strat_train_set.shape)\n",
    "print(strat_test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16512, 10)\n",
      "(4128, 11)\n",
      "(16512, 10)\n",
      "(4128, 10)\n"
     ]
    }
   ],
   "source": [
    "## remove the \"income_cat\" from the stratified sets.\n",
    "## to get the data as earlier.\n",
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"income_cat\", axis = 1, inplace = True)\n",
    "    \n",
    "    print(strat_train_set.shape)\n",
    "    print(strat_test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16512, 10)\n",
      "(4128, 10)\n"
     ]
    }
   ],
   "source": [
    "print(strat_train_set.shape)\n",
    "print(strat_test_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there is on income_cat in the Sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATA CLEANING**\n",
    "\n",
    "+ Starting with Cleaning the Training set.\n",
    "+ Seperate the Predictors and Labels. Since we don't need to apply these transformations to all Attributes.\n",
    "+ Data Cleaning is done on Numerical and Category/Text Attributes Seperately.\n",
    "        + On Numerical :-- Using SimpleImputer.\n",
    "        + On Category/Text :-- Using OrdinalEncoder or OneHotEncorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop the \"mean_house_value\" from the training set.\n",
    "## tehn make a copy of it.\n",
    "housing_data = strat_train_set.drop(\"median_house_value\", axis = 1)\n",
    "housing_labels = housing_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16512, 9)\n",
      "(16512, 9)\n"
     ]
    }
   ],
   "source": [
    "print(housing_data.shape)\n",
    "print(housing_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most ML models cannot work with Missing Features.\n",
    "\n",
    "+ Functionalize to take care of them. :-- Missing Values.\n",
    "\n",
    "+ We had missing values in total_bedrooms attribute Earlier.\n",
    "\n",
    "+ Three options...\n",
    "        + Get rid of the Corresponding Districts.\n",
    "        \n",
    "        + Get rid of the whole Attribute.\n",
    "        \n",
    "        + Set the Values to some values (zero, mean, median etc...)\n",
    "        \n",
    "Three Methods..\n",
    "\n",
    "+ `housing.dropna(subset=[\"total_bedrooms\"])`  :--- Drop Missing Values for Corresponding Districts.\n",
    "+ `housing.drop(\"total_bedrooms\", axis = 1)`   :--- Drop the Entire Column.\n",
    "+ `median = housing[\"total_bedrooms\"].median()`\n",
    "+ `housing[\"total_bedrooms\"].fillna(median, inplace=True)` :--- Imputing with median values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HANDLING NUMERICAL ATTRIBUTES - SIMPLE IMPUTER**\n",
    "\n",
    "Scikit Learn Provides a Handy Class to take Care of Missing Values.\n",
    "\n",
    "+ Create a Simple Imputer Instance.\n",
    "\n",
    "+ Specify you are Replacing missing value with Median.\n",
    "\n",
    "+ Medians can only be Computed on Numerical Attributes.\n",
    "\n",
    "+ So we need to remove the text Attributes from the Dataset for Now.\n",
    "\n",
    "+ eg : ocean_proximity - class attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputer Statistics :-- [-118.51     34.26     29.     2119.5     433.     1164.      408.\n",
      "    3.5409]\n",
      "Median Values which are Calculated :-- [-118.51     34.26     29.     2119.5     433.     1164.      408.\n",
      "    3.5409]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "## initialize the simple imputer instance \n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "## drop the non-numerical attributes for now.\n",
    "housing_numeric_data = housing_data.drop(\"ocean_proximity\", axis = 1)\n",
    "## now fit the imputer instance using fit() method\n",
    "imputer.fit(housing_numeric_data)\n",
    "## here imputer now simply calculated the median,\n",
    "## it will calculate the median for all the numerical attributes.\n",
    "## and will apply imputing to all attributes.\n",
    "print(\"Imputer Statistics :--\",imputer.statistics_)  ## all values will be saved in the statistics.\n",
    "print(\"Median Values which are Calculated :--\",housing_numeric_data.median().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16512, 8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## now use the trained imputer to transform the training set by replacing missing values with the learned medians.\n",
    "X = imputer.transform(housing_numeric_data)\n",
    "X.shape  ## the result will be a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17606</th>\n",
       "      <td>-121.89</td>\n",
       "      <td>37.29</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1568.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>2.7042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18632</th>\n",
       "      <td>-121.93</td>\n",
       "      <td>37.05</td>\n",
       "      <td>14.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>6.4214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14650</th>\n",
       "      <td>-117.20</td>\n",
       "      <td>32.77</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>936.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>2.8621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3230</th>\n",
       "      <td>-119.61</td>\n",
       "      <td>36.31</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1847.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>1.8839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3555</th>\n",
       "      <td>-118.59</td>\n",
       "      <td>34.23</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6592.0</td>\n",
       "      <td>1525.0</td>\n",
       "      <td>4459.0</td>\n",
       "      <td>1463.0</td>\n",
       "      <td>3.0347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "17606    -121.89     37.29                38.0       1568.0           351.0   \n",
       "18632    -121.93     37.05                14.0        679.0           108.0   \n",
       "14650    -117.20     32.77                31.0       1952.0           471.0   \n",
       "3230     -119.61     36.31                25.0       1847.0           371.0   \n",
       "3555     -118.59     34.23                17.0       6592.0          1525.0   \n",
       "\n",
       "       population  households  median_income  \n",
       "17606       710.0       339.0         2.7042  \n",
       "18632       306.0       113.0         6.4214  \n",
       "14650       936.0       462.0         2.8621  \n",
       "3230       1460.0       353.0         1.8839  \n",
       "3555       4459.0      1463.0         3.0347  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## putting the plain Numpy Array to Pandas Dataframe\n",
    "## name = housing_transformed_simpleimputer\n",
    "housing_tr_SI = pd.DataFrame(X, columns = housing_numeric_data.columns, index = housing_numeric_data.index)\n",
    "housing_tr_SI.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ `axis = 0` :-- Verical Axis or Columns.\n",
    "+ `axis = 1` :-- Horizontal Axis or Rows.\n",
    "+ `inplace = True` :-- it will modify the underlying data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HANDLING CATEGORY-/-TEXT ATTRIBUTES**\n",
    "\n",
    "+ There is one text Attribute here :-- \"ocean_proximity\".\n",
    "\n",
    "+ By Checking, they are Category Values.\n",
    "\n",
    "+ Most of ML algorithms prefers to work with Numbers.\n",
    "\n",
    "+ So Converting these Category values to Numbers.\n",
    "\n",
    "+ from text to numbers.\n",
    "\n",
    "\n",
    "\n",
    "**ORDINAL ENCODER**\n",
    "\n",
    "+ Ordianl Encoder used to Convert Categorical Text to Numbers.\n",
    "+ Converting text values to NUmbers using ORDINAL ENCODING.\n",
    "\n",
    "+ There is one issue with this Method.\n",
    "+ ML Algorithms will assume that two nearby values are more similar than two distant values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1H OCEAN     7276\n",
       "INLAND        5263\n",
       "NEAR OCEAN    2124\n",
       "NEAR BAY      1847\n",
       "ISLAND           2\n",
       "Name: ocean_proximity, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_data[\"ocean_proximity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_data_cat = housing_data[[\"ocean_proximity\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vaues:-- [[0.]\n",
      " [0.]\n",
      " [4.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Given Categories:-- [array(['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'],\n",
      "      dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "## initiate the new instance.\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_cat_encoded = ordinal_encoder.fit_transform(housing_data_cat)\n",
    "print(\"Vaues:--\",housing_cat_encoded[:10])\n",
    "print(\"Given Categories:--\",ordinal_encoder.categories_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ONEHOT ENCODER**\n",
    "\n",
    "+ Two avoid the above issue.\n",
    "\n",
    "+ We use OneHotEncoder method.\n",
    "\n",
    "+ Create Binary Attribute per Category.\n",
    "\n",
    "+ Here only one attribute will be having value 1, others will have value 0.\n",
    "\n",
    "+ The new Attributes are Sometimes Called Dummy Attributes.\n",
    "\n",
    "+ Sklearn Provides OneHotEncoder to convert Categorical Attributes to one hot vectors.\n",
    "\n",
    "+ The result will be SciPy Sparse Matrix.\n",
    "\n",
    "+ We get a matrix with 1000s of Columns.\n",
    "\n",
    "+ Single 1 per row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " ...\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "cat_encoder = OneHotEncoder()\n",
    "housing_data_cat_1hot = cat_encoder.fit_transform(housing_data_cat)\n",
    "housing_data_cat_1hot[:10]\n",
    "print(housing_data_cat_1hot.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ If a Categorical Attribute Contain large number of Possible Categories.\n",
    "\n",
    "+ Then one hot encoding will result in a large number of inout features.\n",
    "\n",
    "+ this may slow down the training and degrade perfomance.\n",
    "\n",
    "+ If this happens, you may want to replace the categorical Input with useful numerical features related to Category.\n",
    "\n",
    "+ Here we could replace ocean_proximity feature with the distance to the Ocean.\n",
    "\n",
    "+ Alternatively, you could replace each category with learnable two dimensional vector called Embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CUSTOM TRANSFORMERS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3,4,5,6\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator,TransformerMixin):\n",
    "    \n",
    "    \n",
    "    def __init__(self,add_bedrooms_per_room=True):  ## no *args or **kargs\n",
    "        self.add_bedrooms_per_room=add_bedrooms_per_room\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X,y=None):\n",
    "        rooms_per_household=X[:,rooms_ix]/X[:,households_ix]\n",
    "        population_per_household=X[:,population_ix]/X[:,households_ix]\n",
    "        \n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room=X[:,bedrooms_ix]/X[:,rooms_ix]\n",
    "            return np.c_[X,rooms_per_household,population_per_household,bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X,rooms_per_household,population_per_household]\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
    "housing_extra_attribs=attr_adder.transform(housing_data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[-121.89 37.29 38.0 ... '<1H OCEAN' 4.625368731563422 2.094395280235988]\n",
      " [-121.93 37.05 14.0 ... '<1H OCEAN' 6.008849557522124 2.7079646017699117]\n",
      " [-117.2 32.77 31.0 ... 'NEAR OCEAN' 4.225108225108225 2.0259740259740258]\n",
      " ...\n",
      " [-116.4 34.09 9.0 ... 'INLAND' 6.34640522875817 2.742483660130719]\n",
      " [-118.01 33.82 31.0 ... '<1H OCEAN' 5.50561797752809 3.808988764044944]\n",
      " [-122.45 37.77 52.0 ... 'NEAR BAY' 4.843505477308295 1.9859154929577465]]\n",
      "(16512, 11)\n"
     ]
    }
   ],
   "source": [
    "print(type(housing_extra_attribs))\n",
    "print(housing_extra_attribs)\n",
    "print(housing_extra_attribs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FEATURE SCALING**\n",
    "\n",
    "+ Most Important Transformation you need to apply on your data is Feature Scaling.\n",
    "\n",
    "+ If features have very Different Scale, ML algorithms will not give good Predictions.\n",
    "\n",
    "+ There are two Methods to do this.\n",
    "\n",
    "+ Min-Max Scaling and Standardization.\n",
    "\n",
    "**MIN_MAX SCALING**\n",
    "\n",
    "+ Values are shifted and rescaled so they end up Ranging from 0 to 1.\n",
    "\n",
    "+ Scikit learn Provides transformer Called `MinMaxScaler`.\n",
    "\n",
    "+ It has a feature_range hyperparameter that lets you change the range if you don't want the range 0-1.\n",
    "\n",
    "**STANDARDIZATION**\n",
    "\n",
    "+ Standardized value will be having a Zero mean.\n",
    "\n",
    "+ It Subtract the mean value and divides by the Standard Deviation.\n",
    "\n",
    "+ standardization = (Value - mean Value) / Standard Deviation.\n",
    "\n",
    "+ The resulting Distribution will have Unit variance.\n",
    "\n",
    "+ in Standardization, there will be no range, that will be a problem for Neural Networks.\n",
    "\n",
    "+ Standardization is less affected by Outliers.\n",
    "\n",
    "+ Scikit Learn provides transformer Called `StandardScaler`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRANSFORMATION PIPELINES**\n",
    "\n",
    "+ There are many transformation steps we need to do in an Order.\n",
    "\n",
    "+ Scikit Learn Provides Pipeline class to help with Such sequence of Transfromation.\n",
    "\n",
    "+ When you call pipeline fit() method, it calls the fit_transform() sequentially on all transformers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a Small Pipeline for Numerical Attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numerical_pipeline = Pipeline([\n",
    "    (\"imputer\" , SimpleImputer(strategy=\"median\")),\n",
    "    (\"attribs_adder\" , CombinedAttributesAdder()),\n",
    "    (\"std_scaler\" , StandardScaler())\n",
    "])\n",
    "\n",
    "housing_data_num_transformed = numerical_pipeline.fit_transform(housing_numeric_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16512, 11)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_data_num_transformed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both Numerical and Categorical Attribute transformers in a Single Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numerical_attribs = list(housing_numeric_data)\n",
    "category_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"numeric_values\", numerical_pipeline, numerical_attribs),\n",
    "    (\"categorical_values\", OneHotEncoder(), category_attribs)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prepared = full_pipeline.fit_transform(housing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.15604281  0.77194962  0.74333089 ...  0.          0.\n",
      "   0.        ]\n",
      " [-1.17602483  0.6596948  -1.1653172  ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.18684903 -1.34218285  0.18664186 ...  0.          0.\n",
      "   1.        ]\n",
      " ...\n",
      " [ 1.58648943 -0.72478134 -1.56295222 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.78221312 -0.85106801  0.18664186 ...  0.          0.\n",
      "   0.        ]\n",
      " [-1.43579109  0.99645926  1.85670895 ...  0.          1.\n",
      "   0.        ]]\n",
      "(16512, 16)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(housing_prepared)\n",
    "print(housing_prepared.shape)\n",
    "print(type(housing_prepared))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.15604281,  0.77194962,  0.74333089, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.17602483,  0.6596948 , -1.1653172 , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.18684903, -1.34218285,  0.18664186, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       ...,\n",
       "       [ 1.58648943, -0.72478134, -1.56295222, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.78221312, -0.85106801,  0.18664186, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.43579109,  0.99645926,  1.85670895, ...,  0.        ,\n",
       "         1.        ,  0.        ]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
