{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **SELECT AND TRAIN THE MODEL**\n",
    "\n",
    "+ You framed the Problem.\n",
    "\n",
    "+ You Explored the Data.\n",
    "\n",
    "+ You sampled a training set and test set.\n",
    "\n",
    "+ You wrote Transformation Pipelines.\n",
    "\n",
    "+ You Prepared the Data for ML algos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## fetch the data from the csv file.\n",
    "housing = pd.read_csv(\"housing.csv\")\n",
    "\n",
    "\n",
    "## splitting the data to train set and test set using train test split of sklearn\n",
    "train_set, test_set = train_test_split(housing, test_size = 0.2, random_state = 42)\n",
    "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n",
    "                              bins = [0.0, 1.5, 3.0, 4.5, 6.0, np.inf],\n",
    "                              labels = [1,2,3,4,5])\n",
    "\n",
    "## stratified Splitting, important.\n",
    "split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)\n",
    "\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]\n",
    "## making the data as earlier, remove \"income_cat\"\n",
    "## to get the data as earlier.\n",
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"income_cat\", axis = 1, inplace = True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputer Statistics :-- [-118.51     34.26     29.     2119.5     433.     1164.      408.\n",
      "    3.5409]\n",
      "Median Values which are Calculated :-- [-118.51     34.26     29.     2119.5     433.     1164.      408.\n",
      "    3.5409]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17606</th>\n",
       "      <td>-121.89</td>\n",
       "      <td>37.29</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1568.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>2.7042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18632</th>\n",
       "      <td>-121.93</td>\n",
       "      <td>37.05</td>\n",
       "      <td>14.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>6.4214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14650</th>\n",
       "      <td>-117.20</td>\n",
       "      <td>32.77</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>936.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>2.8621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3230</th>\n",
       "      <td>-119.61</td>\n",
       "      <td>36.31</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1847.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>1.8839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3555</th>\n",
       "      <td>-118.59</td>\n",
       "      <td>34.23</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6592.0</td>\n",
       "      <td>1525.0</td>\n",
       "      <td>4459.0</td>\n",
       "      <td>1463.0</td>\n",
       "      <td>3.0347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "17606    -121.89     37.29                38.0       1568.0           351.0   \n",
       "18632    -121.93     37.05                14.0        679.0           108.0   \n",
       "14650    -117.20     32.77                31.0       1952.0           471.0   \n",
       "3230     -119.61     36.31                25.0       1847.0           371.0   \n",
       "3555     -118.59     34.23                17.0       6592.0          1525.0   \n",
       "\n",
       "       population  households  median_income  \n",
       "17606       710.0       339.0         2.7042  \n",
       "18632       306.0       113.0         6.4214  \n",
       "14650       936.0       462.0         2.8621  \n",
       "3230       1460.0       353.0         1.8839  \n",
       "3555       4459.0      1463.0         3.0347  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## drop the \"mean_house_value\" from the training set.\n",
    "## tehn make a copy of it.\n",
    "housing_data = strat_train_set.drop(\"median_house_value\", axis = 1)\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()\n",
    "\n",
    "\n",
    "\n",
    "## initialize the simple imputer instance \n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "## drop the non-numerical attributes for now.\n",
    "housing_numeric_data = housing_data.drop(\"ocean_proximity\", axis = 1)\n",
    "## now fit the imputer instance using fit() method\n",
    "imputer.fit(housing_numeric_data)\n",
    "## here imputer now simply calculated the median,\n",
    "## it will calculate the median for all the numerical attributes.\n",
    "## and will apply imputing to all attributes.\n",
    "print(\"Imputer Statistics :--\",imputer.statistics_)  ## all values will be saved in the statistics.\n",
    "print(\"Median Values which are Calculated :--\",housing_numeric_data.median().values)\n",
    "\n",
    "## now use the trained imputer to transform the training set by replacing missing values with the learned medians.\n",
    "X = imputer.transform(housing_numeric_data)\n",
    "X.shape  ## the result will be a numpy array.\n",
    "## putting the plain Numpy Array to Pandas Dataframe\n",
    "## name = housing_transformed_simpleimputer\n",
    "housing_tr_SI = pd.DataFrame(X, columns = housing_numeric_data.columns, index = housing_numeric_data.index)\n",
    "housing_tr_SI.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vaues:-- [[0.]\n",
      " [0.]\n",
      " [4.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Given Categories:-- [array(['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'],\n",
      "      dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "## ordinal encoding\n",
    "housing_data_cat = housing_data[[\"ocean_proximity\"]]\n",
    "\n",
    "## initiate the new instance.\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_cat_encoded = ordinal_encoder.fit_transform(housing_data_cat)\n",
    "print(\"Vaues:--\",housing_cat_encoded[:10])\n",
    "print(\"Given Categories:--\",ordinal_encoder.categories_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " ...\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "## one hot encoding\n",
    "\n",
    "cat_encoder = OneHotEncoder()\n",
    "housing_data_cat_1hot = cat_encoder.fit_transform(housing_data_cat)\n",
    "housing_data_cat_1hot[:10]\n",
    "print(housing_data_cat_1hot.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## custom transformers\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3,4,5,6\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator,TransformerMixin):\n",
    "    \n",
    "    \n",
    "    def __init__(self,add_bedrooms_per_room=True):  ## no *args or **kargs\n",
    "        self.add_bedrooms_per_room=add_bedrooms_per_room\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X,y=None):\n",
    "        rooms_per_household=X[:,rooms_ix]/X[:,households_ix]\n",
    "        population_per_household=X[:,population_ix]/X[:,households_ix]\n",
    "        \n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room=X[:,bedrooms_ix]/X[:,rooms_ix]\n",
    "            return np.c_[X,rooms_per_household,population_per_household,bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X,rooms_per_household,population_per_household]\n",
    "        \n",
    "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
    "housing_extra_attribs=attr_adder.transform(housing_data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## simple pipeline\n",
    "\n",
    "\n",
    "numerical_pipeline = Pipeline([\n",
    "    (\"imputer\" , SimpleImputer(strategy=\"median\")),\n",
    "    (\"attribs_adder\" , CombinedAttributesAdder()),\n",
    "    (\"std_scaler\" , StandardScaler())\n",
    "])\n",
    "\n",
    "housing_data_num_transformed = numerical_pipeline.fit_transform(housing_numeric_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "numerical_attribs = list(housing_numeric_data)\n",
    "category_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"numeric_values\", numerical_pipeline, numerical_attribs),\n",
    "    (\"categorical_values\", OneHotEncoder(), category_attribs)\n",
    "])\n",
    "housing_prepared = full_pipeline.fit_transform(housing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.15604281,  0.77194962,  0.74333089, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.17602483,  0.6596948 , -1.1653172 , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.18684903, -1.34218285,  0.18664186, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       ...,\n",
       "       [ 1.58648943, -0.72478134, -1.56295222, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.78221312, -0.85106801,  0.18664186, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.43579109,  0.99645926,  1.85670895, ...,  0.        ,\n",
       "         1.        ,  0.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## from the previous cell,\n",
    "## we have the data to train the model.\n",
    "#print(housing_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRAINING AND EVALUATING ON THE TRAINING SET**\n",
    "\n",
    "Training Linear Regression Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "lin_reg.fit(housing_prepared, housing_labels)\n",
    "\n",
    "housing_predictions = lin_reg.predict(housing_prepared)\n",
    "\n",
    "lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "\n",
    "lin_rmse = np.sqrt(lin_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68628.19819848923"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Most District's median house value is between `$120000` and `$2650000`\n",
    "\n",
    "+ So the prediction `$68628` is not a good one.\n",
    "\n",
    "+ This is an Example of Underfitting.\n",
    "\n",
    "+ Model is Underfitting the Training Data.\n",
    "\n",
    "+ This is because of the features do not provide enough Information to make the good Predictions.\n",
    "\n",
    "+ OR Model is not Powerful enough.\n",
    "\n",
    "+ To fix Underfitting, the methods are \n",
    "\n",
    "        + Select More Powerful Model.\n",
    "        \n",
    "        + Feed model with better features.\n",
    "        \n",
    "        + Reduce the Constraints on the Model.\n",
    "        \n",
    "\n",
    "\n",
    "+ This Model is not Regularized, So last One We can Ignore.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Decision Tree Regressor.\n",
    "\n",
    "+ This is a Powerful Model, Capable of finding Complex Nonlinear Relationships in the Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "\n",
    "tree_reg.fit(housing_prepared, housing_labels)\n",
    "\n",
    "## evaluate.\n",
    "\n",
    "housing_predictions = tree_reg.predict(housing_prepared)\n",
    "\n",
    "tree_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "\n",
    "print(tree_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Here it is showing no Error.\n",
    "\n",
    "+ This is an Example of Overfitting the Data.\n",
    "\n",
    "+ You don't want to touch the test set until you are ready to Launch the model.\n",
    "\n",
    "+ So you need to Use a part of training set for training and part of it for Model Validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CROSS VALIDATION METHOD**\n",
    "\n",
    "+ Cross Validation is a method to Validate the model by splitting the training set to Different folds.\n",
    "\n",
    "+ Here it will Randomly split the training set into different folds.\n",
    "\n",
    "+ then it trains and evaluate the selected ML algorithm for the number of folds. eg 10 here.\n",
    "\n",
    "+ The result is an Array containing 10 evaluating scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    \n",
    "    print(\"Scores :--\",scores)\n",
    "    print(\"The Mean Value :--\",scores.mean())\n",
    "    print(\"The Std Devaition\",scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores :-- [70460.02017297 67729.55444058 72159.53178909 69051.91457446\n",
      " 69527.11053348 73530.36354937 71457.72184771 69128.96105289\n",
      " 76055.38672939 71325.81268787]\n",
      "The Mean Value :-- 71042.63773777967\n",
      "The Std Devaition 2324.9578790664114\n"
     ]
    }
   ],
   "source": [
    "## cross validation done for decision tree model.\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "tree_scores = cross_val_score(tree_reg,\n",
    "                                 housing_prepared,\n",
    "                                 housing_labels,\n",
    "                                 scoring = \"neg_mean_squared_error\",\n",
    "                                 cv = 10)\n",
    "\n",
    "tree_rmse_scores = np.sqrt(-tree_scores)\n",
    "\n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Now the DecisionTreeModel is not looking great.\n",
    "\n",
    "+ Cross Validation Gives two Metrics.\n",
    "\n",
    "    + Validation Scores\n",
    "    + Standard Deviation.\n",
    "    \n",
    "    \n",
    "+ Cross Validation allows you to get not only the Estimate of Perfomance of your Model.\n",
    "\n",
    "+ but also a measure of how precise this estimate.\n",
    "\n",
    "Desicion Tree output = `71042 +- 2324`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores :-- [66782.73843989 66960.118071   70347.95244419 74739.57052552\n",
      " 68031.13388938 71193.84183426 64969.63056405 68281.61137997\n",
      " 71552.91566558 67665.10082067]\n",
      "The Mean Value :-- 69052.46136345083\n",
      "The Std Devaition 2731.6740017983484\n"
     ]
    }
   ],
   "source": [
    "## computing score for linear model.\n",
    "\n",
    "lin_scores = cross_val_score(lin_reg,\n",
    "                                housing_prepared,\n",
    "                                housing_labels,\n",
    "                                scoring = \"neg_mean_squared_error\",\n",
    "                                cv = 10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression Output = `69052 +- 2731`\n",
    "\n",
    "+ The Decision tree model is Overfitting badly.\n",
    "\n",
    "+ It performs worstly than Linear Regression Model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Regressor Model.\n",
    "\n",
    "+ Random Forest works by training many Decision Trees on random subsets of features, then averaging out their predictions.\n",
    "\n",
    "+ Building a model on top of other Models is called Ensemble Learning.\n",
    "\n",
    "+ We will get better Perfomance by this Way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18671.50930417007"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "\n",
    "forest_reg.fit(housing_prepared, housing_labels)\n",
    "\n",
    "housing_predictions = forest_reg.predict(housing_prepared)\n",
    "\n",
    "forest_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores :-- [49535.30665498 47427.08974674 50042.62400595 52404.14851748\n",
      " 49570.51903801 53647.32101315 48573.99115511 47868.05724351\n",
      " 53010.14366044 50150.82269695]\n",
      "The Mean Value :-- 50223.00237323133\n",
      "The Std Devaition 2031.50317120755\n"
     ]
    }
   ],
   "source": [
    "##definnig forest score using cross validation method.\n",
    "\n",
    "forest_scores = cross_val_score(forest_reg,\n",
    "                                   housing_prepared,\n",
    "                                   housing_labels,\n",
    "                                   scoring = \"neg_mean_squared_error\",\n",
    "                                   cv = 10)\n",
    "\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest output :-- `50223 +- 2031`\n",
    "\n",
    "\n",
    "+ Random Forest looks very Promising.\n",
    "\n",
    "+ Score on training set is still much lower than the validation set.\n",
    "\n",
    "+ ie, the model is still overfitting the training set.\n",
    "\n",
    "+ Possible Solutions for Overfitting problems:--\n",
    "\n",
    "    + Simplify the Model.\n",
    "    \n",
    "    + Constraint the Model (Regularize the Model).\n",
    "    \n",
    "    + Get more training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying out more Models like.\n",
    "\n",
    "+ Support Vector Machine :-- with Different Kernel.\n",
    "\n",
    "+ Neural Network :-- without much tweaking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111094.6308539982\n"
     ]
    }
   ],
   "source": [
    "## using the kernel = linear\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svm_reg = SVR(kernel = \"linear\")\n",
    "\n",
    "svm_reg.fit(housing_prepared, housing_labels)\n",
    "\n",
    "housing_predictions = svm_reg.predict(housing_prepared)\n",
    "\n",
    "svm_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "\n",
    "svm_rmse = np.sqrt(svm_mse)\n",
    "\n",
    "print(svm_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores :-- [105342.09141998 112489.24624123 110092.35042753 113403.22892482\n",
      " 110638.90119657 115675.8320024  110703.56887243 114476.89008206\n",
      " 113756.17971227 111520.1120808 ]\n",
      "The Mean Value :-- 111809.84009600841\n",
      "The Std Devaition 2762.393664321567\n"
     ]
    }
   ],
   "source": [
    "svm_scores = cross_val_score(svm_reg,\n",
    "                                housing_prepared,\n",
    "                                housing_labels,\n",
    "                                scoring = \"neg_mean_squared_error\",\n",
    "                                cv = 10)\n",
    "\n",
    "svm_rmse_scores = np.sqrt(-svm_scores)\n",
    "display_scores(svm_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM output :-- `111809 +- 2762`\n",
    "\n",
    "+ The kernel used here is \"linear\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118580.68301157995\n"
     ]
    }
   ],
   "source": [
    "## using the kernel = \"rbf\"\n",
    "\n",
    "## using the kernel = linear\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svm_reg_rbf = SVR(kernel = \"rbf\")\n",
    "\n",
    "svm_reg_rbf.fit(housing_prepared, housing_labels)\n",
    "\n",
    "housing_predictions = svm_reg_rbf.predict(housing_prepared)\n",
    "\n",
    "svm_mse_rbf = mean_squared_error(housing_labels, housing_predictions)\n",
    "\n",
    "svm_rmse_rbf = np.sqrt(svm_mse_rbf)\n",
    "\n",
    "print(svm_rmse_rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores :-- [111389.0681902  119541.25938571 116957.62830414 120447.19932481\n",
      " 117618.15904234 122309.10351544 117634.40230741 121469.713921\n",
      " 120343.01369623 118017.12860651]\n",
      "The Mean Value :-- 118572.66762937943\n",
      "The Std Devaition 2936.8775867949425\n"
     ]
    }
   ],
   "source": [
    "svm_rbf_scores = cross_val_score(svm_reg_rbf,\n",
    "                                housing_prepared,\n",
    "                                housing_labels,\n",
    "                                scoring = \"neg_mean_squared_error\",\n",
    "                                cv = 10)\n",
    "\n",
    "svm_rmse_rbf_scores = np.sqrt(-svm_rbf_scores)\n",
    "display_scores(svm_rmse_rbf_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM Output :-- `118572 +- 2936`\n",
    "\n",
    "+ The kernel used here is \"rbf\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trained 4 Models.**\n",
    "\n",
    "\n",
    "+ Linear Regression :-- Output = `69052 +- 2731`\n",
    "\n",
    "+ Decision Tree Regression :-- Output =  `71042 +- 2324`\n",
    "\n",
    "+ Random Forest Regression :-- Output = `50223 +- 2031`\n",
    "\n",
    "+ Support Vector Machine :-- Output = `111809 +- 2762` with kernel `linear`\n",
    "\n",
    "+ Support Vector Machine :-- Output = `118572 +- 2936` with kernel `rbf`\n",
    "\n",
    "Here the best model is SVM with kernel rbf.\n",
    "\n",
    "+ Because it has an Output almost the average of housing price in the City."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SAVE THE MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(lin_reg, \"linear_Regression.pkl\")\n",
    "my_model_loaded = joblib.load(\"linear_Regression.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(tree_reg, \"DecisionTree_Regression.pkl\")\n",
    "my_model_loaded = joblib.load(\"DecisionTree_Regression.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(forest_reg, \"RandomForest.pkl\")\n",
    "my_model_loaded = joblib.load(\"RandomForest.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(svm_reg, \"SVM_linear.pkl\")\n",
    "my_model_loaded = joblib.load(\"SV\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
