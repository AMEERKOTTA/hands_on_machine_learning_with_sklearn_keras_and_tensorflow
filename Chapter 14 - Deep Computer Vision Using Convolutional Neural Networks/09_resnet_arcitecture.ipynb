{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESNET ARCHITECTURE\n",
    "\n",
    "+ Resnet is Very Deep CNN model.\n",
    "+ Models are getting Deeper and Deeper, with fewer and fewer parameters.\n",
    "+ The Key to train such NN is to use Skip Connections.\n",
    "\n",
    "*WHAT IS RESIDUAL LEARNING*\n",
    "\n",
    "+ when training the neural network, the goal is to make the model a target function $$h(x)$$\n",
    "+ If yo add the input to the Output Network.\n",
    "+ Then the Network will be forced to model. $$f(x) = h(x) - x$$\n",
    "+ This is called Residual Learning.\n",
    "\n",
    "*RESNET ARCHITECTURE*\n",
    "\n",
    "+ It Starts and Ends like Google Net Architecture.\n",
    "+ In between is just very deep stack of Simple Residual Units.\n",
    "\n",
    "+ *RESIDUAL UNITS*\n",
    "    \n",
    "     + Composed of two Convolutional Layers.\n",
    "     + No Pooling Layers.\n",
    "     + with Batch Normalization.\n",
    "     + Using ReLU activation function.\n",
    "     + Using 3x3 Kernel.\n",
    "     + Preserving Spatial Dimensions.\n",
    "     \n",
    "*RESNET - 34*\n",
    "\n",
    "+ ResNet with 34 Layers.\n",
    "+ Only contains the Conv Layer and Fully Connected Layer.\n",
    "+ 3 RU s and 64 feature maps.\n",
    "+ 4 RU s and 128 feature maps.\n",
    "+ 6 RU s with 256 maps.\n",
    "+ 3 RU s with 512 maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DefaultConv2D = partial(keras.layers.Conv2D, kernel_size=3, strides=1,\n",
    "                        padding=\"SAME\", use_bias=False)\n",
    "\n",
    "class ResidualUnit(keras.layers.Layer):\n",
    "    def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        self.main_layers = [\n",
    "            DefaultConv2D(filters, strides=strides),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            self.activation,\n",
    "            DefaultConv2D(filters),\n",
    "            keras.layers.BatchNormalization()]\n",
    "        self.skip_layers = []\n",
    "        if strides > 1:\n",
    "            self.skip_layers = [\n",
    "                DefaultConv2D(filters, kernel_size=1, strides=strides),\n",
    "                keras.layers.BatchNormalization()]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.main_layers:\n",
    "            Z = layer(Z)\n",
    "        skip_Z = inputs\n",
    "        for layer in self.skip_layers:\n",
    "            skip_Z = layer(skip_Z)\n",
    "        return self.activation(Z + skip_Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(DefaultConv2D(64, kernel_size=7, strides=2,\n",
    "                        input_shape=[224, 224, 3]))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Activation(\"relu\"))\n",
    "model.add(keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"SAME\"))\n",
    "prev_filters = 64\n",
    "for filters in [64] * 3 + [128] * 4 + [256] * 6 + [512] * 3:\n",
    "    strides = 1 if filters == prev_filters else 2\n",
    "    model.add(ResidualUnit(filters, strides=strides))\n",
    "    prev_filters = filters\n",
    "model.add(keras.layers.GlobalAvgPool2D())\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_5 (Conv2D)           (None, 112, 112, 64)      9408      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 112, 112, 64)     256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 56, 56, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " residual_unit (ResidualUnit  (None, 56, 56, 64)       74240     \n",
      " )                                                               \n",
      "                                                                 \n",
      " residual_unit_1 (ResidualUn  (None, 56, 56, 64)       74240     \n",
      " it)                                                             \n",
      "                                                                 \n",
      " residual_unit_2 (ResidualUn  (None, 56, 56, 64)       74240     \n",
      " it)                                                             \n",
      "                                                                 \n",
      " residual_unit_3 (ResidualUn  (None, 28, 28, 128)      230912    \n",
      " it)                                                             \n",
      "                                                                 \n",
      " residual_unit_4 (ResidualUn  (None, 28, 28, 128)      295936    \n",
      " it)                                                             \n",
      "                                                                 \n",
      " residual_unit_5 (ResidualUn  (None, 28, 28, 128)      295936    \n",
      " it)                                                             \n",
      "                                                                 \n",
      " residual_unit_6 (ResidualUn  (None, 28, 28, 128)      295936    \n",
      " it)                                                             \n",
      "                                                                 \n",
      " residual_unit_7 (ResidualUn  (None, 14, 14, 256)      920576    \n",
      " it)                                                             \n",
      "                                                                 \n",
      " residual_unit_8 (ResidualUn  (None, 14, 14, 256)      1181696   \n",
      " it)                                                             \n",
      "                                                                 \n",
      " residual_unit_9 (ResidualUn  (None, 14, 14, 256)      1181696   \n",
      " it)                                                             \n",
      "                                                                 \n",
      " residual_unit_10 (ResidualU  (None, 14, 14, 256)      1181696   \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " residual_unit_11 (ResidualU  (None, 14, 14, 256)      1181696   \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " residual_unit_12 (ResidualU  (None, 14, 14, 256)      1181696   \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " residual_unit_13 (ResidualU  (None, 7, 7, 512)        3676160   \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " residual_unit_14 (ResidualU  (None, 7, 7, 512)        4722688   \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " residual_unit_15 (ResidualU  (None, 7, 7, 512)        4722688   \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,306,826\n",
      "Trainable params: 21,289,802\n",
      "Non-trainable params: 17,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
