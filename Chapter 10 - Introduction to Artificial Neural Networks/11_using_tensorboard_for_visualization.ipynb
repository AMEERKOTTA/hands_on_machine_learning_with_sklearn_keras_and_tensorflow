{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USING TENSORBOARD FOR VISUALIZATION\n",
    "\n",
    "+ TensorBoard is a great Interactive Visualization that can use for viewing the\n",
    "    + learning curve during training\n",
    "    + compare learning curves between multiple runs\n",
    "    + visulize the computation graph\n",
    "    + analyze training statistics\n",
    "    + view images generated by the model\n",
    "    + visualize complex multidimensional data projected down to 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2023_02_02-11_44_04'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================Shape of the Full Training and Test Set======================\n",
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n",
      "===================Shape of the Training and Test Set after the Splitting to Validation Set======================\n",
      "(5000, 28, 28)\n",
      "(55000, 28, 28)\n",
      "(5000,)\n",
      "(55000,)\n",
      "['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot']\n",
      "7\n",
      "Coat\n",
      "Sneaker\n",
      "==============Building the Model using Sequntial API=======================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "[<keras.layers.reshaping.flatten.Flatten object at 0x000001B125A46040>, <keras.layers.core.dense.Dense object at 0x000001B140F96EE0>, <keras.layers.core.dense.Dense object at 0x000001B140F92DF0>, <keras.layers.core.dense.Dense object at 0x000001B140F96FA0>]\n",
      "dense\n",
      "[[ 0.02608864 -0.04254158 -0.0500663  ...  0.03292537 -0.04992773\n",
      "   0.06316315]\n",
      " [-0.03035282  0.06429666 -0.07268902 ... -0.03605492  0.06917715\n",
      "  -0.01852006]\n",
      " [ 0.05553454 -0.02588693 -0.04031814 ... -0.05777501 -0.03389888\n",
      "   0.03379233]\n",
      " ...\n",
      " [ 0.06097279  0.06733057  0.00776727 ...  0.03349877  0.06379774\n",
      "  -0.03347949]\n",
      " [ 0.03125925 -0.06209439 -0.02406933 ... -0.02962995 -0.01617192\n",
      "   0.03486358]\n",
      " [ 0.01259476 -0.03860513  0.06166168 ...  0.04309298  0.03856206\n",
      "  -0.02564837]]\n",
      "(784, 300)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "(300,)\n",
      "=================Compiling the model=====================\n",
      "================Use Callbacks============================\n",
      "================USING EARLY STOPPING METHODS===============\n",
      "================Training the Model=======================\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.7166 - accuracy: 0.7655 - val_loss: 0.4973 - val_accuracy: 0.8348\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.4897 - accuracy: 0.8293 - val_loss: 0.4456 - val_accuracy: 0.8516\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.4435 - accuracy: 0.8449 - val_loss: 0.4144 - val_accuracy: 0.8582\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4155 - accuracy: 0.8541 - val_loss: 0.3903 - val_accuracy: 0.8690\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3934 - accuracy: 0.8615 - val_loss: 0.4064 - val_accuracy: 0.8534\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3790 - accuracy: 0.8661 - val_loss: 0.3776 - val_accuracy: 0.8698\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3644 - accuracy: 0.8710 - val_loss: 0.3596 - val_accuracy: 0.8750\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3541 - accuracy: 0.8746 - val_loss: 0.3641 - val_accuracy: 0.8740\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3433 - accuracy: 0.8777 - val_loss: 0.3493 - val_accuracy: 0.8758\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3346 - accuracy: 0.8803 - val_loss: 0.3413 - val_accuracy: 0.8796\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3261 - accuracy: 0.8835 - val_loss: 0.3320 - val_accuracy: 0.8836\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3199 - accuracy: 0.8850 - val_loss: 0.3246 - val_accuracy: 0.8836\n",
      "Epoch 13/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3116 - accuracy: 0.8891 - val_loss: 0.3484 - val_accuracy: 0.8782\n",
      "Epoch 14/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3049 - accuracy: 0.8903 - val_loss: 0.3304 - val_accuracy: 0.8852\n",
      "Epoch 15/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2989 - accuracy: 0.8936 - val_loss: 0.3238 - val_accuracy: 0.8842\n",
      "Epoch 16/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2928 - accuracy: 0.8939 - val_loss: 0.3133 - val_accuracy: 0.8852\n",
      "Epoch 17/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2862 - accuracy: 0.8973 - val_loss: 0.3409 - val_accuracy: 0.8716\n",
      "Epoch 18/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2812 - accuracy: 0.8995 - val_loss: 0.3183 - val_accuracy: 0.8840\n",
      "Epoch 19/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2764 - accuracy: 0.9005 - val_loss: 0.3079 - val_accuracy: 0.8888\n",
      "Epoch 20/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2708 - accuracy: 0.9022 - val_loss: 0.3024 - val_accuracy: 0.8886\n",
      "Epoch 21/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2656 - accuracy: 0.9046 - val_loss: 0.3043 - val_accuracy: 0.8898\n",
      "Epoch 22/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2618 - accuracy: 0.9055 - val_loss: 0.3002 - val_accuracy: 0.8914\n",
      "Epoch 23/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2572 - accuracy: 0.9073 - val_loss: 0.3021 - val_accuracy: 0.8892\n",
      "Epoch 24/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2515 - accuracy: 0.9104 - val_loss: 0.3007 - val_accuracy: 0.8898\n",
      "Epoch 25/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2477 - accuracy: 0.9105 - val_loss: 0.3073 - val_accuracy: 0.8862\n",
      "Epoch 26/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2438 - accuracy: 0.9126 - val_loss: 0.3001 - val_accuracy: 0.8910\n",
      "Epoch 27/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2397 - accuracy: 0.9140 - val_loss: 0.2964 - val_accuracy: 0.8924\n",
      "Epoch 28/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2365 - accuracy: 0.9143 - val_loss: 0.2945 - val_accuracy: 0.8930\n",
      "Epoch 29/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.2313 - accuracy: 0.9177 - val_loss: 0.3237 - val_accuracy: 0.8850\n",
      "Epoch 30/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2290 - accuracy: 0.9184 - val_loss: 0.3169 - val_accuracy: 0.8806\n",
      "Epoch 31/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2251 - accuracy: 0.9185 - val_loss: 0.2979 - val_accuracy: 0.8934\n",
      "Epoch 32/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2217 - accuracy: 0.9214 - val_loss: 0.3180 - val_accuracy: 0.8806\n",
      "Epoch 33/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2184 - accuracy: 0.9211 - val_loss: 0.2939 - val_accuracy: 0.8906\n",
      "Epoch 34/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2145 - accuracy: 0.9223 - val_loss: 0.3183 - val_accuracy: 0.8900\n",
      "Epoch 35/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2102 - accuracy: 0.9239 - val_loss: 0.2939 - val_accuracy: 0.8922\n",
      "Epoch 36/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2075 - accuracy: 0.9253 - val_loss: 0.2914 - val_accuracy: 0.8912\n",
      "Epoch 37/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2051 - accuracy: 0.9257 - val_loss: 0.2930 - val_accuracy: 0.8928\n",
      "Epoch 38/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2009 - accuracy: 0.9280 - val_loss: 0.2977 - val_accuracy: 0.8950\n",
      "Epoch 39/100\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.1980 - accuracy: 0.9292 - val_loss: 0.2902 - val_accuracy: 0.8958\n",
      "Epoch 40/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.1956 - accuracy: 0.9298 - val_loss: 0.2939 - val_accuracy: 0.8940\n",
      "Epoch 41/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.1935 - accuracy: 0.9312 - val_loss: 0.2834 - val_accuracy: 0.8986\n",
      "Epoch 42/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.1887 - accuracy: 0.9325 - val_loss: 0.2855 - val_accuracy: 0.8936\n",
      "Epoch 43/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.1865 - accuracy: 0.9338 - val_loss: 0.3132 - val_accuracy: 0.8922\n",
      "Epoch 44/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1831 - accuracy: 0.9353 - val_loss: 0.3063 - val_accuracy: 0.8922\n",
      "Epoch 45/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1808 - accuracy: 0.9357 - val_loss: 0.2802 - val_accuracy: 0.8988\n",
      "Epoch 46/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.1780 - accuracy: 0.9363 - val_loss: 0.2812 - val_accuracy: 0.9002\n",
      "Epoch 47/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1764 - accuracy: 0.9369 - val_loss: 0.2900 - val_accuracy: 0.8976\n",
      "Epoch 48/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1724 - accuracy: 0.9391 - val_loss: 0.2845 - val_accuracy: 0.8988\n",
      "Epoch 49/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1704 - accuracy: 0.9390 - val_loss: 0.2811 - val_accuracy: 0.8978\n",
      "Epoch 50/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1673 - accuracy: 0.9405 - val_loss: 0.3062 - val_accuracy: 0.8882\n",
      "Epoch 51/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1640 - accuracy: 0.9418 - val_loss: 0.2837 - val_accuracy: 0.9004\n",
      "Epoch 52/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1612 - accuracy: 0.9428 - val_loss: 0.2948 - val_accuracy: 0.8968\n",
      "Epoch 53/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1587 - accuracy: 0.9442 - val_loss: 0.2938 - val_accuracy: 0.8970\n",
      "Epoch 54/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1571 - accuracy: 0.9442 - val_loss: 0.2939 - val_accuracy: 0.8902\n",
      "Epoch 55/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1540 - accuracy: 0.9457 - val_loss: 0.2902 - val_accuracy: 0.9026\n"
     ]
    }
   ],
   "source": [
    "## use keras to load the dataset\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "print(\"===================Shape of the Full Training and Test Set======================\")\n",
    "print(X_train_full.shape)\n",
    "print(y_train_full.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "## the dataset is already splitted to training and test set.\n",
    "## now the data is to be splitted to validation set.\n",
    "X_valid, X_train = X_train_full[:5000]/255.0, X_train_full[5000:]/255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "print(\"===================Shape of the Training and Test Set after the Splitting to Validation Set======================\")\n",
    "print(X_valid.shape)\n",
    "print(X_train.shape)\n",
    "print(y_valid.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "## for fashion mnist, the class names are\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle Boot\"]\n",
    "print(class_names)\n",
    "\n",
    "## first example in the trainning set \n",
    "print(y_train[2])\n",
    "print(class_names[y_train[0]])\n",
    "print(class_names[y_train[2]])\n",
    "\n",
    "print(\"==============Building the Model using Sequntial API=======================\")\n",
    "##defining the model\n",
    "## this is the line to reate the sequential model\n",
    "## simplest kind of keras model for neural networks, this is called sequential API.\n",
    "model = keras.models.Sequential()\n",
    "## First Layer is Flatten Layer\n",
    "## This will convert each input image to 1D array.\n",
    "## here we have to specify the input shape  = (28,28)\n",
    "## we dont need to give the batch size here. only the input shape.\n",
    "## alternatively we can give keras.layers.InputLayer(input_shape=[28,28])\n",
    "model.add(keras.layers.Flatten(input_shape = [28,28]))\n",
    "## next layer is dense layer with 300 neurons.\n",
    "## it will use ReLU activation function.\n",
    "model.add(keras.layers.Dense(300, activation = \"relu\"))\n",
    "## next layer is also a Dense layer with 100 neurons\n",
    "## it also uses the ReLU activation function.\n",
    "model.add(keras.layers.Dense(100, activation = \"relu\"))\n",
    "## next layer is the final layer with 10 neurons. to classify the 10 classes.\n",
    "## here using the softmax actiavtion function.\n",
    "model.add(keras.layers.Dense(10, activation = \"softmax\"))\n",
    "\n",
    "# ## we can do the same thing in the given below manner as well\n",
    "# model = keras.models.Sequential([\n",
    "#     keras.layers.Flatten(input_shape=[28,28]),\n",
    "#     keras.layers.Dense(300, activation = \"relu\"),\n",
    "#     keras.layers.Dense(100, activation = \"relu\"),\n",
    "#     keras.layers.Dense(10, activation = \"softmax\")\n",
    "# ])\n",
    "\n",
    "## printing the model summary\n",
    "print(model.summary())\n",
    "## print the model layers\n",
    "print(model.layers)\n",
    "## check the first hidden layer\n",
    "hidden1 = model.layers[1]\n",
    "print(hidden1.name)\n",
    "## checking the weights and biases.\n",
    "weights, biases = hidden1.get_weights()\n",
    "print(weights)\n",
    "print(weights.shape)\n",
    "print(biases)\n",
    "print(biases.shape)\n",
    "\n",
    "print(\"=================Compiling the model=====================\")\n",
    "## compile the model\n",
    "## compile is to specify the loss fnuction and optimizer to use while training and evaluating.\n",
    "## also we can give the metrics to use while training and evaluating model.\n",
    "## using loss = \"sparse_categorical_crossentropy\"\n",
    "## using optimizer as \"sgd\" which is stochcastic gradient descent.\n",
    "## using the metrics as \"accuracy\"\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\",\n",
    "                 optimizer = \"sgd\",\n",
    "                 metrics = [\"accuracy\"])\n",
    "\n",
    "print(\"================Use Callbacks============================\")\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"fashion_mnist_classifier_model_earlystopping_and_tesnorboard.h5\", save_best_only=True)\n",
    "print(\"================USING EARLY STOPPING METHODS===============\")\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "print(\"================Training the Model=======================\")\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs = 100, \n",
    "                    validation_data = [X_valid, y_valid],\n",
    "                    callbacks=[checkpoint_cb,early_stopping_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 12252), started 0:01:15 ago. (Use '!kill 12252' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e1cf0da515a4160d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e1cf0da515a4160d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
