{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NON SATURATING ACTIVATION FUNCTIONS\n",
    "\n",
    "+ List of Activation Function available in keras is given below.\n",
    "\n",
    "*WHAT IS DYING RELU*\n",
    "\n",
    "+ during training, some neurons effectively die.\n",
    "+ they stop outputting anything otherthan 0.\n",
    "+ when this happens, gradient descent does not affect anymore\n",
    "+ It will not work properly\n",
    "\n",
    "*LEAKY RELU*\n",
    "\n",
    "+ to solve the above problem.\n",
    "+ the activation function we use is called leaky relu.\n",
    "+ leaky relu always outperfomed the strict RELU function.\n",
    "\n",
    "*ELU - Exponential Linear Unit*\n",
    "\n",
    "+ ELU outperformed all the ReLU variants.\n",
    "+ Training time was Reduced.\n",
    "+ Neural Networks Performed better on the Test Sets.\n",
    "\n",
    "*SELU - scaled Variant of ELU*\n",
    "\n",
    "+ scaled variant of ELU\n",
    "\n",
    "*BACTH NORMALIZATION*\n",
    "\n",
    "+ Batch Normalization is also used to Improve the Model.\n",
    "+ By eliminating the Vanishing Gradient and Exploding Gradient Problems.\n",
    "+ It is done by adding Batch Normalization layers before and after the Activation function layer.\n",
    "\n",
    "Sometimes applying BN before the activation function works better (there's a debate on this topic). Moreover, the layer before a BatchNormalization layer does not need to have bias terms, since the BatchNormalization layer has some as well, it would be a waste of parameters, so you can set use_bias=False when creating those layers:\n",
    "\n",
    "`model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(100, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])`\n",
    "\n",
    "*GRADIENT CLIPPING*\n",
    "\n",
    "+ method to solve exploding gradient.\n",
    "+ this is done by clipping the gradient descent.\n",
    "+ so that they never exceeds some threshold.\n",
    "+ this technique is more used in RNNs.\n",
    "+ Batch Normalization is tricky to use in RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deserialize',\n",
       " 'elu',\n",
       " 'exponential',\n",
       " 'gelu',\n",
       " 'get',\n",
       " 'hard_sigmoid',\n",
       " 'linear',\n",
       " 'relu',\n",
       " 'selu',\n",
       " 'serialize',\n",
       " 'sigmoid',\n",
       " 'softmax',\n",
       " 'softplus',\n",
       " 'softsign',\n",
       " 'swish',\n",
       " 'tanh']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_functions = [act_fun for act_fun in dir(keras.activations) if not act_fun.startswith(\"_\")]\n",
    "activation_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LEAKY RELU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def leaky_relu(z, alpha=0.01):\n",
    "    return np.maximum(alpha*z, z)\n",
    "\n",
    "## plot the leaky relu\n",
    "z = np.linspace(-5, 5, 200)\n",
    "plt.plot(z, leaky_relu(z, 0.05), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([0, 0], [-0.5, 4.2], 'k-')\n",
    "plt.grid(True)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Leak', xytext=(-3.5, 0.5), xy=(-5, -0.2), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.title(\"Leaky ReLU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.5, 4.2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 28, 28)\n",
      "(55000,)\n",
      "(5000, 28, 28)\n",
      "(5000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n",
      "=================MODEL DEVELOPMENT================\n",
      "=================COMPILE THE MODEL=================\n",
      "=================TRAIN THE MODEL===================\n",
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 5s 2ms/step - loss: 1.3056 - accuracy: 0.6056 - val_loss: 0.8839 - val_accuracy: 0.7196\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.7913 - accuracy: 0.7447 - val_loss: 0.7069 - val_accuracy: 0.7680\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6750 - accuracy: 0.7797 - val_loss: 0.6379 - val_accuracy: 0.7928\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6158 - accuracy: 0.7970 - val_loss: 0.5861 - val_accuracy: 0.8084\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5783 - accuracy: 0.8082 - val_loss: 0.5555 - val_accuracy: 0.8188\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5514 - accuracy: 0.8150 - val_loss: 0.5335 - val_accuracy: 0.8240\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5312 - accuracy: 0.8212 - val_loss: 0.5152 - val_accuracy: 0.8316\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5155 - accuracy: 0.8256 - val_loss: 0.5097 - val_accuracy: 0.8316\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5030 - accuracy: 0.8289 - val_loss: 0.4914 - val_accuracy: 0.8374\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4920 - accuracy: 0.8315 - val_loss: 0.4835 - val_accuracy: 0.8400\n"
     ]
    }
   ],
   "source": [
    "## implementing the leaky relu activation function in the model\n",
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print(\"=================MODEL DEVELOPMENT================\")\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "print(\"=================COMPILE THE MODEL=================\")\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "print(\"=================TRAIN THE MODEL===================\")\n",
    "history = model.fit(X_train, y_train, epochs=10,validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRYING THE PRELU ACTIVATION FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================MODEL DEVELOPMENT================\n",
      "=================COMPILE THE MODEL=================\n",
      "=================TRAIN THE MODEL===================\n",
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 5s 2ms/step - loss: 1.3627 - accuracy: 0.5800 - val_loss: 0.9319 - val_accuracy: 0.6922\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.8341 - accuracy: 0.7254 - val_loss: 0.7449 - val_accuracy: 0.7558\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.7099 - accuracy: 0.7721 - val_loss: 0.6689 - val_accuracy: 0.7872\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6426 - accuracy: 0.7921 - val_loss: 0.6076 - val_accuracy: 0.8034\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5983 - accuracy: 0.8039 - val_loss: 0.5703 - val_accuracy: 0.8146\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5663 - accuracy: 0.8121 - val_loss: 0.5437 - val_accuracy: 0.8206\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5422 - accuracy: 0.8185 - val_loss: 0.5212 - val_accuracy: 0.8282\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5236 - accuracy: 0.8240 - val_loss: 0.5109 - val_accuracy: 0.8306\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5088 - accuracy: 0.8274 - val_loss: 0.4915 - val_accuracy: 0.8382\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4962 - accuracy: 0.8305 - val_loss: 0.4828 - val_accuracy: 0.8398\n"
     ]
    }
   ],
   "source": [
    "print(\"=================MODEL DEVELOPMENT================\")\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "print(\"=================COMPILE THE MODEL=================\")\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "print(\"=================TRAIN THE MODEL===================\")\n",
    "history = model.fit(X_train, y_train, epochs=10,validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ELU - Exponential Linear Unit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def elu(z, alpha=1):\n",
    "    return np.where(z < 0, alpha * (np.exp(z) - 1), z)\n",
    "\n",
    "## plotting the ELU\n",
    "plt.plot(z, elu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1, -1], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"ELU activation function ($\\alpha=1$)\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================MODEL DEVELOPMENT================\n",
      "=================COMPILE THE MODEL=================\n",
      "=================TRAIN THE MODEL===================\n",
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 1.3846 - accuracy: 0.5888 - val_loss: 0.9273 - val_accuracy: 0.7146\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.8223 - accuracy: 0.7429 - val_loss: 0.7238 - val_accuracy: 0.7690\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6929 - accuracy: 0.7785 - val_loss: 0.6482 - val_accuracy: 0.7866\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.6277 - accuracy: 0.7978 - val_loss: 0.5921 - val_accuracy: 0.8070\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5862 - accuracy: 0.8090 - val_loss: 0.5582 - val_accuracy: 0.8212\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5566 - accuracy: 0.8166 - val_loss: 0.5338 - val_accuracy: 0.8246\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.5343 - accuracy: 0.8223 - val_loss: 0.5139 - val_accuracy: 0.8300\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5168 - accuracy: 0.8271 - val_loss: 0.5046 - val_accuracy: 0.8332\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5027 - accuracy: 0.8302 - val_loss: 0.4874 - val_accuracy: 0.8346\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4905 - accuracy: 0.8341 - val_loss: 0.4789 - val_accuracy: 0.8386\n"
     ]
    }
   ],
   "source": [
    "## implementing methods for ELU\n",
    "keras.layers.Dense(10, activation=\"elu\")\n",
    "\n",
    "print(\"=================MODEL DEVELOPMENT================\")\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "print(\"=================COMPILE THE MODEL=================\")\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "print(\"=================TRAIN THE MODEL===================\")\n",
    "history = model.fit(X_train, y_train, epochs=10,validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SELU - scaled Variant of ELU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================MODEL DEVELOPMENT========================\n",
      "=================COMPILE THE MODEL=========================\n",
      "=================TRAIN THE MODEL===========================\n",
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 25s 13ms/step - loss: 1.1694 - accuracy: 0.5669 - val_loss: 1.0183 - val_accuracy: 0.6178\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 20s 12ms/step - loss: 0.7604 - accuracy: 0.7282 - val_loss: 0.6138 - val_accuracy: 0.7796\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 21s 12ms/step - loss: 0.6048 - accuracy: 0.7853 - val_loss: 0.5561 - val_accuracy: 0.8052\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 21s 12ms/step - loss: 0.5504 - accuracy: 0.8074 - val_loss: 0.5273 - val_accuracy: 0.8192\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 21s 12ms/step - loss: 0.5004 - accuracy: 0.8266 - val_loss: 0.4854 - val_accuracy: 0.8330\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 21s 12ms/step - loss: 0.4722 - accuracy: 0.8342 - val_loss: 0.4541 - val_accuracy: 0.8412\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 21s 12ms/step - loss: 0.4372 - accuracy: 0.8467 - val_loss: 0.4343 - val_accuracy: 0.8480\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 21s 12ms/step - loss: 0.4170 - accuracy: 0.8523 - val_loss: 0.4679 - val_accuracy: 0.8396\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 21s 12ms/step - loss: 0.4008 - accuracy: 0.8568 - val_loss: 0.4194 - val_accuracy: 0.8540\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 22s 13ms/step - loss: 0.3830 - accuracy: 0.8641 - val_loss: 0.4189 - val_accuracy: 0.8540\n"
     ]
    }
   ],
   "source": [
    "print(\"=================MODEL DEVELOPMENT========================\")\n",
    "## implementing selu activation function\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "## defining selu activation function\n",
    "model.add(keras.layers.Dense(300, activation=\"selu\",kernel_initializer=\"lecun_normal\"))\n",
    "for layer in range(99):\n",
    "    model.add(keras.layers.Dense(100, activation=\"selu\",kernel_initializer=\"lecun_normal\"))\n",
    "## final layer using softmax activation function itself\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "print(\"=================COMPILE THE MODEL=========================\")\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "print(\"=================TRAIN THE MODEL===========================\")\n",
    "## Now let's train it. Do not forget to scale the inputs to mean 0 and standard deviation 1:\n",
    "pixel_means = X_train.mean(axis=0, keepdims=True)\n",
    "pixel_stds = X_train.std(axis=0, keepdims=True)\n",
    "X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
    "X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
    "X_test_scaled = (X_test - pixel_means) / pixel_stds\n",
    "\n",
    "## train the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=10,validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================MODEL DEVELOPMENT========================\n",
      "=================COMPILE THE MODEL=========================\n",
      "=================TRAIN THE MODEL===========================\n",
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 21s 10ms/step - loss: 2.0168 - accuracy: 0.2048 - val_loss: 2.1770 - val_accuracy: 0.1158\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 1.4604 - accuracy: 0.3866 - val_loss: 1.1570 - val_accuracy: 0.5318\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 1.1557 - accuracy: 0.5152 - val_loss: 0.9410 - val_accuracy: 0.6008\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 18s 10ms/step - loss: 0.9652 - accuracy: 0.5973 - val_loss: 0.8563 - val_accuracy: 0.6508\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 18s 10ms/step - loss: 0.8648 - accuracy: 0.6523 - val_loss: 0.8450 - val_accuracy: 0.6418\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 18s 10ms/step - loss: 0.8639 - accuracy: 0.6626 - val_loss: 0.8675 - val_accuracy: 0.6130\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 18s 10ms/step - loss: 0.8780 - accuracy: 0.6597 - val_loss: 0.7080 - val_accuracy: 0.7154\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 18s 10ms/step - loss: 0.8026 - accuracy: 0.6870 - val_loss: 0.7963 - val_accuracy: 0.7136\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 18s 10ms/step - loss: 0.8062 - accuracy: 0.6831 - val_loss: 0.8426 - val_accuracy: 0.6778\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 18s 10ms/step - loss: 0.8375 - accuracy: 0.6702 - val_loss: 0.7087 - val_accuracy: 0.7164\n"
     ]
    }
   ],
   "source": [
    "print(\"=================MODEL DEVELOPMENT========================\")\n",
    "## implementing selu activation function\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "## defining selu activation function\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\",kernel_initializer=\"he_normal\"))\n",
    "for layer in range(99):\n",
    "    model.add(keras.layers.Dense(100, activation=\"relu\",kernel_initializer=\"he_normal\"))\n",
    "## final layer using softmax activation function itself\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "print(\"=================COMPILE THE MODEL=========================\")\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "print(\"=================TRAIN THE MODEL===========================\")\n",
    "## train the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=10,validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HERE WE ARE SUFFERING FROM VANISHING OR EXPLODING GRADIENT PROBLEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BATCH NORMALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================MODEL DEVELOPMENT=========================\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_13 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 784)              3136      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_336 (Dense)           (None, 300)               235500    \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 300)              1200      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_337 (Dense)           (None, 100)               30100     \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_338 (Dense)           (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n",
      "None\n",
      "=====================COMPILE THE MODEL==========================\n",
      "=====================TRAIN THE MODEL============================\n",
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 7s 3ms/step - loss: 0.8522 - accuracy: 0.7111 - val_loss: 0.5673 - val_accuracy: 0.8124\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5807 - accuracy: 0.7978 - val_loss: 0.4879 - val_accuracy: 0.8360\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5261 - accuracy: 0.8170 - val_loss: 0.4503 - val_accuracy: 0.8462\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4869 - accuracy: 0.8286 - val_loss: 0.4281 - val_accuracy: 0.8522\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4608 - accuracy: 0.8388 - val_loss: 0.4124 - val_accuracy: 0.8594\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4435 - accuracy: 0.8429 - val_loss: 0.4020 - val_accuracy: 0.8620\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4297 - accuracy: 0.8474 - val_loss: 0.3911 - val_accuracy: 0.8660\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4179 - accuracy: 0.8517 - val_loss: 0.3870 - val_accuracy: 0.8674\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4067 - accuracy: 0.8549 - val_loss: 0.3788 - val_accuracy: 0.8678\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3956 - accuracy: 0.8586 - val_loss: 0.3722 - val_accuracy: 0.8694\n"
     ]
    }
   ],
   "source": [
    "print(\"=====================MODEL DEVELOPMENT=========================\")\n",
    "## trying the batch normalization in simple terms\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "print(model.summary())\n",
    "bn1 = model.layers[1]\n",
    "[(var.name, var.trainable) for var in bn1.variables]\n",
    "\n",
    "print(\"=====================COMPILE THE MODEL==========================\")\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "print(\"=====================TRAIN THE MODEL============================\")\n",
    "history = model.fit(X_train, y_train, epochs=10,validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================MODEL DEVELOPMENT=========================\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_14 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 784)              3136      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_339 (Dense)           (None, 300)               235200    \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 300)              1200      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation (Activation)     (None, 300)               0         \n",
      "                                                                 \n",
      " dense_340 (Dense)           (None, 100)               30000     \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_341 (Dense)           (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 270,946\n",
      "Trainable params: 268,578\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n",
      "None\n",
      "=====================COMPILE THE MODEL==========================\n",
      "=====================TRAIN THE MODEL============================\n",
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 7s 3ms/step - loss: 1.0179 - accuracy: 0.6813 - val_loss: 0.6592 - val_accuracy: 0.7914\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.6668 - accuracy: 0.7840 - val_loss: 0.5443 - val_accuracy: 0.8194\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5881 - accuracy: 0.8034 - val_loss: 0.4934 - val_accuracy: 0.8334\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5379 - accuracy: 0.8189 - val_loss: 0.4612 - val_accuracy: 0.8416\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5061 - accuracy: 0.8263 - val_loss: 0.4393 - val_accuracy: 0.8496\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4867 - accuracy: 0.8323 - val_loss: 0.4223 - val_accuracy: 0.8570\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4692 - accuracy: 0.8377 - val_loss: 0.4086 - val_accuracy: 0.8600\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4538 - accuracy: 0.8425 - val_loss: 0.3992 - val_accuracy: 0.8632\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4420 - accuracy: 0.8473 - val_loss: 0.3901 - val_accuracy: 0.8648\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4298 - accuracy: 0.8505 - val_loss: 0.3835 - val_accuracy: 0.8650\n"
     ]
    }
   ],
   "source": [
    "## different method for batch normalization\n",
    "print(\"=====================MODEL DEVELOPMENT=========================\")\n",
    "## trying the batch normalization in simple terms\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(100, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "print(model.summary())\n",
    "bn1 = model.layers[1]\n",
    "[(var.name, var.trainable) for var in bn1.variables]\n",
    "\n",
    "print(\"=====================COMPILE THE MODEL==========================\")\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "print(\"=====================TRAIN THE MODEL============================\")\n",
    "history = model.fit(X_train, y_train, epochs=10,validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRADIENT CLIPPING\n",
    "\n",
    "+ `optimizer = keras.optimizers.SGD(clipvalue=1.0)`\n",
    "+ `optimizer = keras.optimizers.SGD(clipnorm=1.0)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================MODEL DEVELOPMENT=========================\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_15 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 784)              3136      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_342 (Dense)           (None, 300)               235200    \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 300)              1200      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 300)               0         \n",
      "                                                                 \n",
      " dense_343 (Dense)           (None, 100)               30000     \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_344 (Dense)           (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 270,946\n",
      "Trainable params: 268,578\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n",
      "None\n",
      "=====================COMPILE THE MODEL==========================\n",
      "=====================TRAIN THE MODEL============================\n",
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 1.0773 - accuracy: 0.6681 - val_loss: 0.6840 - val_accuracy: 0.7894\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.6875 - accuracy: 0.7826 - val_loss: 0.5577 - val_accuracy: 0.8194\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.6009 - accuracy: 0.8037 - val_loss: 0.5010 - val_accuracy: 0.8348\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5475 - accuracy: 0.8195 - val_loss: 0.4680 - val_accuracy: 0.8412\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5137 - accuracy: 0.8263 - val_loss: 0.4445 - val_accuracy: 0.8480\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4912 - accuracy: 0.8331 - val_loss: 0.4276 - val_accuracy: 0.8532\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4728 - accuracy: 0.8392 - val_loss: 0.4141 - val_accuracy: 0.8550\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4587 - accuracy: 0.8435 - val_loss: 0.4048 - val_accuracy: 0.8560\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4448 - accuracy: 0.8484 - val_loss: 0.3959 - val_accuracy: 0.8572\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4334 - accuracy: 0.8494 - val_loss: 0.3870 - val_accuracy: 0.8622\n"
     ]
    }
   ],
   "source": [
    "## different method for batch normalization\n",
    "print(\"=====================MODEL DEVELOPMENT=========================\")\n",
    "## trying the batch normalization in simple terms\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(100, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "print(model.summary())\n",
    "bn1 = model.layers[1]\n",
    "[(var.name, var.trainable) for var in bn1.variables]\n",
    "\n",
    "print(\"=====================COMPILE THE MODEL==========================\")\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3, clipvalue=1.0),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "print(\"=====================TRAIN THE MODEL============================\")\n",
    "history = model.fit(X_train, y_train, epochs=10,validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
